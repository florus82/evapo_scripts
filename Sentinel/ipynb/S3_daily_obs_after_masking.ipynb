{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b976a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/users/potzschf/conda/envs/workhorse/lib/python3.12/site-packages/osgeo/ogr.py:601: FutureWarning: Neither ogr.UseExceptions() nor ogr.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.guzinski import *\n",
    "from helperToolz.dicts_and_lists import INT_TO_MONTH\n",
    "\n",
    "# set storPath for exported tiffs\n",
    "LST_path = '/data/Aldhani/eoagritwin/et/Sentinel3/raw_LST/'\n",
    "VZA_path = '/data/Aldhani/eoagritwin/et/Sentinel3/VZA/monthly_tiff_values/'\n",
    "AirTemp_path = '/data/Aldhani/eoagritwin/et/Auxiliary/ERA5/tiff/low_res/2m_temperature/'\n",
    "\n",
    "storPath_base = '/data/Aldhani/eoagritwin/et/Sentinel3/LST/Analytics/guzinski_masking/'\n",
    "# for year in [2019]:\n",
    "year = 2019\n",
    "\n",
    "# get a temporal subset of LST, VZA and air temp files for that year\n",
    "files = sorted(getFilelist(LST_path, '.nc'))\n",
    "yearFiles_LST = [file for file in sorted(getFilelist(LST_path, '.nc')) if int(file.split('/')[-1].split('_')[-1][0:4]) == year]\n",
    "yearFiles_VZA = getFilelist(f'{VZA_path}{year}/', 'tif')\n",
    "yearFiles_2mT = getFilelist(f'{AirTemp_path}{year}', '.tif')\n",
    "\n",
    "mask = makeGermanyMaskforNC('/data/Aldhani/eoagritwin/misc/gadm41_DEU_shp/gadm41_DEU_0.shp', yearFiles_LST[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8bff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearList = []\n",
    "for month in [f'{i:02d}' for i in range(1,13)]:\n",
    "    if month != '07':\n",
    "        continue\n",
    "    if growingSeasonChecker(int(month)):\n",
    "        \n",
    "        # subset LST to month and get acquisition time and calculate observations per day\n",
    "        file_LST = [yearfile_LST for yearfile_LST in yearFiles_LST if f'{month}.nc' == yearfile_LST.split('-')[-1]][0]\n",
    "        accDateTimes = getAllDatesS3(file_LST) \n",
    "        df = pd.Series(accDateTimes)\n",
    "        counts_per_day = df.dt.floor(\"D\").value_counts().sort_index()\n",
    "        # make iterables from counts per day that catch starting and ending indices to subset all obs per day\n",
    "        cumulative_day_counts_end = np.asarray(np.cumsum(counts_per_day))\n",
    "        cumulative_day_counts_start = np.insert(cumulative_day_counts_end, 0 ,0)\n",
    "\n",
    "        # load data (/all observations for that month)\n",
    "        dat_LST = getDataFromNC_LST(file_LST)\n",
    "\n",
    "        # apply the temperature threshold\n",
    "        dat_LST[dat_LST<273.15] = np.nan # LST_MASKING check!\n",
    "\n",
    "        # get VZA stack and 2m airtemperature mask\n",
    "        file_VZA = [yearfile_VZA for yearfile_VZA in yearFiles_VZA if f'{month}.tif' == yearfile_VZA.split('_')[-1]][0]\n",
    "        dat_VZA = stackReader(file_VZA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04399cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "month='07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c658dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check air temperature (2m ERA5)\n",
    "file_2mT = [yearFile_2mT for yearFile_2mT in yearFiles_2mT if f'{INT_TO_MONTH[month]}.tif' == yearFile_2mT.split('_')[-1]][0]\n",
    "dat_2mT, time_2mT = stackReader(file_2mT, bands=True)\n",
    "\n",
    "#### get ERA5 AirTemp (interpolated from both modelled values that are closest to LST)\n",
    "bands_low = []\n",
    "minutes = [] # get the minutes to interpolate ERA5 temp values to the exact minute of LST acquisition\n",
    "for accDT in accDateTimes: # search for each LST observation\n",
    "    for count, air_time in enumerate(time_2mT): # the two neighbouting ERA5 air temp values\n",
    "        if accDT.astype('datetime64[h]')== pd.Timestamp(air_time): # this will get the hourly value before the acquisition\n",
    "            bands_low.append(count)\n",
    "            minutes.append(pd.Timestamp(accDT).minute)\n",
    "bands_up = [band + 1 for band in bands_low]# this get the hourly value after the acquisition\n",
    "\n",
    "# interpolate to the minute of observation\n",
    "air_temp_intpol = dat_2mT[:,:,bands_low] - (dat_2mT[:,:,bands_low] - dat_2mT[:,:,bands_up]) * (np.array(minutes, dtype=np.float32) / 60).reshape(1,1,-1) # add one dimension for broadcasting\n",
    "\n",
    "# apply air threshold\n",
    "dat_LST = np.where((dat_LST - air_temp_intpol) < -2, np.nan, dat_LST)\n",
    "\n",
    "# now get composites (minVZA, maxLST, single scenes)\n",
    "\n",
    "count_list = []\n",
    "doyL = [] # for band names when exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearList = []\n",
    "for month in [f'{i:02d}' for i in range(1,13)]:\n",
    "    if month != '07':\n",
    "        continue\n",
    "    if growingSeasonChecker(int(month)):\n",
    "        \n",
    "        # subset LST to month and get acquisition time and calculate observations per day\n",
    "        file_LST = [yearfile_LST for yearfile_LST in yearFiles_LST if f'{month}.nc' == yearfile_LST.split('-')[-1]][0]\n",
    "        accDateTimes = getAllDatesS3(file_LST) \n",
    "        df = pd.Series(accDateTimes)\n",
    "        counts_per_day = df.dt.floor(\"D\").value_counts().sort_index()\n",
    "        # make iterables from counts per day that catch starting and ending indices to subset all obs per day\n",
    "        cumulative_day_counts_end = np.asarray(np.cumsum(counts_per_day))\n",
    "        cumulative_day_counts_start = np.insert(cumulative_day_counts_end, 0 ,0)\n",
    "\n",
    "        # load data (/all observations for that month)\n",
    "        dat_LST = getDataFromNC_LST(file_LST)\n",
    "\n",
    "        # apply the temperature threshold\n",
    "        dat_LST[dat_LST<273.15] = np.nan # LST_MASKING check!\n",
    "\n",
    "        # get VZA stack and 2m airtemperature mask\n",
    "        file_VZA = [yearfile_VZA for yearfile_VZA in yearFiles_VZA if f'{month}.tif' == yearfile_VZA.split('_')[-1]][0]\n",
    "        dat_VZA = stackReader(file_VZA)\n",
    "\n",
    "        # sanity check\n",
    "        if (dat_LST.shape == dat_VZA.shape):\n",
    "    \n",
    "            # check air temperature (2m ERA5)\n",
    "            file_2mT = [yearFile_2mT for yearFile_2mT in yearFiles_2mT if f'{INT_TO_MONTH[month]}.tif' == yearFile_2mT.split('_')[-1]][0]\n",
    "            dat_2mT, time_2mT = stackReader(file_2mT, bands=True)\n",
    "\n",
    "            #### get ERA5 AirTemp (interpolated from both modelled values that are closest to LST)\n",
    "            bands_low = []\n",
    "            minutes = [] # get the minutes to interpolate ERA5 temp values to the exact minute of LST acquisition\n",
    "            for accDT in accDateTimes: # search for each LST observation\n",
    "                for count, air_time in enumerate(time_2mT): # the two neighbouting ERA5 air temp values\n",
    "                    if accDT.astype('datetime64[h]')== pd.Timestamp(air_time): # this will get the hourly value before the acquisition\n",
    "                        bands_low.append(count)\n",
    "                        minutes.append(pd.Timestamp(accDT).minute)\n",
    "            bands_up = [band + 1 for band in bands_low]# this get the hourly value after the acquisition\n",
    "            \n",
    "            # interpolate to the minute of observation\n",
    "            air_temp_intpol = dat_2mT[:,:,bands_low] - (dat_2mT[:,:,bands_low] - dat_2mT[:,:,bands_up]) * (np.array(minutes, dtype=np.float32) / 60).reshape(1,1,-1) # add one dimension for broadcasting\n",
    "\n",
    "            # apply air threshold\n",
    "            dat_LST = np.where((dat_LST - air_temp_intpol) < -2, np.nan, dat_LST)\n",
    "\n",
    "            # now get composites (minVZA, maxLST, single scenes)\n",
    "            \n",
    "            count_list = []\n",
    "            doyL = [] # for band names when exporting\n",
    "\n",
    "            for l in range(len(counts_per_day)):\n",
    "\n",
    "                ################## LST values\n",
    "                # Select the slices for the day:\n",
    "                LST_slice = dat_LST[:, :, cumulative_day_counts_start[l]:cumulative_day_counts_end[l]]  # shape (X,Y,Z)\n",
    "                VZA_slice = dat_VZA[:, :, cumulative_day_counts_start[l]:cumulative_day_counts_end[l]]  # shape (X,Y,Z)\n",
    "\n",
    "                # Create mask where LST is valid and VZA < 45\n",
    "                valid_mask = (~np.isnan(LST_slice)) & (VZA_slice < 45)\n",
    "                valid_obs = np.sum(valid_mask, axis=2) * mask\n",
    "                count_list.append(valid_obs)\n",
    "\n",
    "                doyL.append(f'DOY_{l+1}')\n",
    "                yearList.append(valid_obs)\n",
    "\n",
    "                lst_to_export = np.where(valid_mask, LST_slice, np.nan)\n",
    "\n",
    "                npTOdisk(lst_to_export, f'{storPath_base}Daily_Observation_Guzinski_mask_{year}_{INT_TO_MONTH[month]}.tif',\n",
    "                f\"/data/Aldhani/eoagritwin/et/Sentinel3/temp/guzinski_masked_single_scenes/{file_LST.split('.nc')[0].split('/')[-1]}.tif\",\n",
    "                bands=lst_to_export.shape[2], bandnames=df[cumulative_day_counts_start[l]:cumulative_day_counts_end[l]])\n",
    "                \n",
    "\n",
    "#         exportNCarrayDerivatesInt(file_LST, storPath_base, f'Daily_Observation_Guzinski_mask_{year}_{INT_TO_MONTH[month]}.tif',\n",
    "#                           doyL, np.dstack(count_list), numberOfBands=len(count_list))\n",
    "            \n",
    "# exportNCarrayDerivatesInt(file_LST, storPath_base, f'April-October_Cumulative_Observation_Guzinski_mask_{year}_{INT_TO_MONTH[month]}.tif',\n",
    "#                           f'Cumulative_Observations in growing season {year}', np.sum(np.dstack(yearList),axis=2), numberOfBands=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f7089f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc4288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(len(counts_per_day)):\n",
    "\n",
    "    ################## LST values\n",
    "    # Select the slices for the day:\n",
    "    LST_slice = dat_LST[:, :, cumulative_day_counts_start[l]:cumulative_day_counts_end[l]]  # shape (X,Y,Z)\n",
    "    VZA_slice = dat_VZA[:, :, cumulative_day_counts_start[l]:cumulative_day_counts_end[l]]  # shape (X,Y,Z)\n",
    "\n",
    "    # Create mask where LST is valid and VZA < 45\n",
    "    valid_mask = (~np.isnan(LST_slice)) & (VZA_slice < 45)\n",
    "    valid_obs = np.sum(valid_mask, axis=2) * mask\n",
    "    count_list.append(valid_obs)\n",
    "\n",
    "    doyL.append(f'DOY_{l+1}')\n",
    "    yearList.append(valid_obs)\n",
    "\n",
    "    lst_to_export = np.where(valid_mask, LST_slice, np.nan)\n",
    "\n",
    "    npTOdisk(lst_to_export, f'{storPath_base}Daily_Observation_Guzinski_mask_{year}_{INT_TO_MONTH[month]}.tif',\n",
    "    f\"/data/Aldhani/eoagritwin/et/Sentinel3/temp/guzinski_masked_single_scenes/{file_LST.split('.nc')[0].split('/')[-1]}_day_{l+1}.tif\",\n",
    "    bands=lst_to_export.shape[2], bandnames=df[cumulative_day_counts_start[l]:cumulative_day_counts_end[l]].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e91350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 8\n",
    "################# LST values\n",
    "# Select the slices for the day:\n",
    "LST_slice = dat_LST[:, :, cumulative_day_counts_start[l]:cumulative_day_counts_end[l]]  # shape (X,Y,Z)\n",
    "VZA_slice = dat_VZA[:, :, cumulative_day_counts_start[l]:cumulative_day_counts_end[l]]  # shape (X,Y,Z)\n",
    "\n",
    "# Create mask where LST is valid and VZA < 45\n",
    "valid_mask = (~np.isnan(LST_slice)) & (VZA_slice < 45)\n",
    "valid_obs = np.sum(valid_mask, axis=2) * mask\n",
    "count_list.append(valid_obs)\n",
    "\n",
    "doyL.append(f'DOY_{l+1}')\n",
    "yearList.append(valid_obs)\n",
    "\n",
    "lst_to_export = np.where(valid_mask, LST_slice, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7082d7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(26136040.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nansum(lst_to_export[:,:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76ca3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npTOdisk(arr, reference_path, outPath, bands = False, bandnames = False):\n",
    "    \"\"\"exports a numpy array to a tif that is stored on disk\n",
    "\n",
    "    Args:\n",
    "        arr (numpy array): the array to be exported\n",
    "        reference_path (str): path to the reference tif. The extent and dimensions must fit!!!!\n",
    "        outPath (_str): path to exported tif on disk\n",
    "    \"\"\"\n",
    "    ref_ds = checkPath(reference_path)\n",
    "    ref_band = ref_ds.GetRasterBand(1)\n",
    "    if not bands:\n",
    "        bands = ref_ds.RasterCount\n",
    "    out_ds = gdal.GetDriverByName('GTiff').Create(outPath, ref_ds.RasterXSize, ref_ds.RasterYSize, bands, ref_band.DataType)\n",
    "    out_ds.SetGeoTransform(ref_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ref_ds.GetProjection())\n",
    "    if bands == 1:\n",
    "        out_ds.GetRasterBand(1).WriteArray(arr)\n",
    "        if bandnames:\n",
    "                out_ds.GetRasterBand(1).SetDescription(bandnames)\n",
    "    else:\n",
    "        for i in range(bands):\n",
    "            out_ds.GetRasterBand(i+1).WriteArray(arr[:,:,i])\n",
    "            if bandnames:\n",
    "                out_ds.GetRasterBand(i+1).SetDescription(str(bandnames[i]))\n",
    "    out_ds.FlushCache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ystack = np.dstack(yearList)\n",
    "# ystack[ystack>0] = 1\n",
    "\n",
    "# exportNCarrayDerivatesInt(file_LST, storPath_base, f'April-October_Amount_days_with_Observation_Guzinski_mask_{year}_{INT_TO_MONTH[month]}.tif',\n",
    "#                           f'Amount_days_with_Observations in growing season {year}', np.sum(ystack,axis=2), numberOfBands=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

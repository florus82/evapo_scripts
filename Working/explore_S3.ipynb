{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Auxiliary/')\n",
    "from helpsters import *\n",
    "# import packages \n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.transform import from_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(getFilelist('/data/Aldhani/eoagritwin/et/Sentinel3/raw', '.nc'))\n",
    "year = 2024\n",
    "# get a subset of files for that year\n",
    "yearFiles = [file for file in files if int(file.split('/')[-1].split('_')[-1][0:4]) == year]\n",
    "\n",
    "# make dictionary that stores .tif names and related accDates to easier search to close observations with S2 data\n",
    "keys = ['filename', 'accDateTimes']\n",
    "vals = [list() for i in range(len(keys))]\n",
    "lookUp = dict(zip(keys, vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set storPath for exported tiffs\n",
    "storPath = '/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/lst/'\n",
    "cont = []\n",
    "# loop over files and export to .tif at location storPath\n",
    "for file in yearFiles:\n",
    "\n",
    "    accDateTimes = getAllDatesS3(file) # possible to take annual subset if entire files list would be passed here\n",
    "    convertNCtoTIF(file, storPath, file.split('/')[-1].split('.')[0] + '.tif', accDateTimes, False, True)\n",
    "\n",
    "    # # write filenames and corresponding dates into dictionary for easier datesearch later\n",
    "    # lookUp['filename'].append(file.split('.nc')[0])\n",
    "    # lookUp['accDateTimes'].append(accDateTimes)\n",
    "\n",
    "\n",
    "    # cont = []\n",
    "   \n",
    "    # #for file in yearFiles:\n",
    "    # aa  = getDataFromNC(file)\n",
    "    # accDateTimes = getAllDatesS3(file)\n",
    "    # df = pd.Series(accDateTimes)\n",
    "    # counts_per_day = df.dt.floor(\"D\").value_counts().sort_index()\n",
    "    # t2 = np.cumsum(counts_per_day)\n",
    "    # t1 = np.insert(t2, 0 ,0)\n",
    "\n",
    "    # for l in range(len(counts_per_day)):\n",
    "    #     # cont.append(np.any(~np.isnan(aa[:, :, t1[l]:t2[l]]),axis=2)) minimum dail obs\n",
    "    #     cont.append(np.nansum(~np.isnan(aa[:, :, t1[l]:t2[l]]),axis=2))\n",
    "\n",
    "    # exportNCarrayDerivatesInt(file, storPath, f'Minimum_DailyObservations_{('_').join(file.split('_')[-1].split('-')[:2])}.tif', 'monthly_sum_of_daily_obs', np.nansum(np.dstack((cont)), axis = 2), True)\n",
    "#xportNCarrayDerivatesInt(file, storPath, f'Minimum_DailyObservations_{file.split('_')[-1].split('-')[0]}.tif', 'annual_sum_of_daily_obs', np.nansum(np.dstack((cont)), axis = 2), True)\n",
    "#exportNCarrayDerivatesInt(file, storPath, f'DailyObservations_{file.split('_')[-1].split('-')[0]}.tif', 'annual_sum_of_all_daily_obs', np.nansum(np.dstack((cont)), axis = 2), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.asarray((np.nan))\n",
    "dat.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile = xr.open_dataset(yearFiles[0])\n",
    "arr = ncfile[[b for b in ','.join(ncfile.data_vars.keys()).split(',') if b == 'confidence_in'][0]].to_numpy() \n",
    "np.unique(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evapo_sentinelhub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

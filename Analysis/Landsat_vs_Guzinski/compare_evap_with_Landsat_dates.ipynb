{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1812ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import * \n",
    "import geopandas as gpd\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71da5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Landsat_pattern = r\"\\d{4}_\\d{2}_\\d{1,2}\"\n",
    "Landsat_folder = '/data/Aldhani/eoagritwin/et/Landsat/daily_extracts/Brandenburg/2019/'\n",
    "\n",
    "guz_pattern = r\"20\\d{2}_[A-Z][a-z]+_\\d{2}\"\n",
    "\n",
    "daily_LS = [file for file in getFilelist(Landsat_folder, '.tif', deep=True)]\n",
    "all_LS_dates = re.findall(Landsat_pattern, \" \".join(daily_LS))\n",
    "all_LS_dates = [datetime.strptime(str(compDate), '%Y_%m_%d') for compDate in all_LS_dates]\n",
    "\n",
    "mask_ds = gdal.Open('/data/Aldhani/eoagritwin/fields/Auxiliary/grid_search/Brandenburg/quick_n_dirty/Fields_as_mask_pixel_20.tif')\n",
    "mask_arr = mask_ds.GetRasterBand(1).ReadAsArray()\n",
    "mask_arr[mask_arr>0] = 1\n",
    "\n",
    "# Number of strata and samples per stratum\n",
    "n_strata = 10\n",
    "samples_per_stratum = 1000\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_guz_Dates = []\n",
    "\n",
    "for comp in ['maxLST', 'minVZA']:\n",
    "    pathi = '/data/Aldhani/eoagritwin/et/Sentinel3/LST/SharpEvap/Brandenburg/FirstShot/evap/'\n",
    "    vrt_folder= f'{pathi}{comp}/vrt/'\n",
    "\n",
    "    daily_Canopy = [file for file in getFilelist(vrt_folder, '.vrt', deep=True) if '_calc_' in file and 'Canopy' in file]\n",
    "    daily_Soil = [file for file in getFilelist(vrt_folder, '.vrt', deep=True) if '_calc_' in file and 'Soil' in file]\n",
    "\n",
    "    for daily_C in daily_Canopy:\n",
    "        for daily_S in daily_Soil:\n",
    "\n",
    "            # find date matching soil and canopy files\n",
    "            if daily_C.split('Canopy_')[-1] == daily_S.split('Soil_')[-1]:\n",
    "\n",
    "                # get the date as time object\n",
    "                g_date = datetime.strptime(str(daily_C.split('Canopy_calc_')[-1].split('.')[0]), '%Y_%B_%d')\n",
    "\n",
    "                # check if a landsat image exists for that date\n",
    "                if g_date in all_LS_dates:\n",
    "                    print(g_date)\n",
    "\n",
    "                    # add soil and canopy\n",
    "                    arr_C = stackReader(checkPath(daily_C))\n",
    "                    arr_S = stackReader(checkPath(daily_S))\n",
    "                    guz_arr = arr_C + arr_S\n",
    "                    guz_arr_masked = guz_arr * mask_arr\n",
    "                    guz_arr_masked = np.where(guz_arr_masked > 0, guz_arr_masked, np.nan)\n",
    "\n",
    "                    # load and warp landsat to match estimation\n",
    "                    LS_Match = daily_LS[all_LS_dates.index(g_date)]\n",
    "                    LandS_arr = stackReader(checkPath(LS_Match))\n",
    "                    warped_LandS_arr = warp_np_to_reference(LandS_arr, LS_Match, target_tif_path=daily_C)\n",
    "                    warped_masked_LandS = warped_LandS_arr * mask_arr\n",
    "\n",
    "                    # Compute percentile thresholds\n",
    "                    percentiles = np.nanpercentile(guz_arr_masked, np.linspace(0, 100, n_strata + 1))\n",
    "                    print(percentiles)\n",
    "                    for i in range(n_strata):\n",
    "\n",
    "                        lower, upper = percentiles[i], percentiles[i + 1]\n",
    "                        stratum_mask = (guz_arr_masked >= lower) & (guz_arr_masked < upper) & (warped_masked_LandS > 0) & (~np.isnan(warped_masked_LandS))\n",
    "\n",
    "                        idx = np.argwhere(stratum_mask)\n",
    "\n",
    "                        chosen_idx = idx[np.random.choice(len(idx), min(samples_per_stratum, len(idx)), replace=False)]\n",
    "\n",
    "                        chosen_landsat = warped_masked_LandS[chosen_idx[:,0], chosen_idx[:,1]]\n",
    "                        chosen_evapo_est = guz_arr_masked[chosen_idx[:,0], chosen_idx[:,1]]\n",
    "                        \n",
    "                        for pix in range(len(chosen_landsat)):\n",
    "                        \n",
    "                            results.append({\n",
    "                                'Date': g_date.strftime('%Y_%m_%d'),\n",
    "                                'Stratum': f'{i}_{i+1}th',\n",
    "                                'Landsat': chosen_landsat[pix],\n",
    "                                'Guzinski': chosen_evapo_est[pix],\n",
    "                                'row': chosen_idx[pix][0],\n",
    "                                'col': chosen_idx[pix][1],\n",
    "                                'comp': comp\n",
    "                            })\n",
    "\n",
    "                else:\n",
    "                    print('no landsat scene at that day :(')\n",
    "\n",
    "# convert and export\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f'daily_extracts.csv', index=False)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35b0d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/potzschf/repos/evapo_scripts/Analysis/Landsat_vs_Guzinski'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3179ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /home/potzschf/repos/evapo_scripts/Analysis/Landsat_vs_Guzinski/compare_evap_with_Landsat_dates.ipynb to script\n",
      "[NbConvertApp] Writing 4652 bytes to /home/potzschf/repos/evapo_scripts/Analysis/Landsat_vs_Guzinski/compare_evap_with_Landsat_dates.py.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script /home/potzschf/repos/evapo_scripts/Analysis/Landsat_vs_Guzinski/compare_evap_with_Landsat_dates.ipynb --output /home/potzschf/repos/evapo_scripts/Analysis/Landsat_vs_Guzinski/compare_evap_with_Landsat_dates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

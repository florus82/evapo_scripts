{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b02694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import warp_ERA5_to_reference\n",
    "import pvlib\n",
    "from pvlib import solarposition\n",
    "from pvlib.irradiance import get_total_irradiance\n",
    "from pvlib.location import Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7feef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if downloaded ERA5 variables acutally contain more than just one value for the study period\n",
    "base_path = '/data/Aldhani/eoagritwin/et/Auxiliary/ERA5/grib/'\n",
    "variables = [name for name in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b357d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "month = 'July'\n",
    "doy = 26\n",
    "comp = 'maxLST'\n",
    "tempOut = '/data/Aldhani/eoagritwin/et/Auxiliary/trash/'\n",
    "file = [file for file in getFilelist(os.path.join(base_path, 'surface_solar_radiation_downward_clear_sky'), '.grib') if str(year) in file and str(int(MONTH_TO_02D[month])) in file][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c8af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/reprojected/DEM_GER_FORCE_WARP.tif' # epsg 4326\n",
    "slope_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/reprojected/SLOPE_GER_FORCE_WARP.tif' # epsg 4326\n",
    "aspect_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/reprojected/ASPECT_GER_FORCE_WARP.tif' # epsg 4326\n",
    "lat_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/reprojected/LAT_GER_FORCE_WARP.tif' # epsg 4326\n",
    "lon_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/reprojected/LON_GER_FORCE_WARP.tif' # epsg 4326\n",
    "\n",
    "# the geopotential is needed for the sharpening as well\n",
    "geopot_path = '/data/Aldhani/eoagritwin/et/Auxiliary/ERA5/tiff/low_res/geopotential/geopotential_low_res.tif' # epsg 4326\n",
    "s2_pathbase = f'/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/tempDump2/ff3f2c872c08977466e5a8dc306d2d2aabc77ad995b0716c30d1c57d0004ebfd/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5f8e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/users/potzschf/conda/envs/cds_era5/lib/python3.12/site-packages/osgeo/gdal.py:311: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LST_acq_file = f'/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/Acq_time/int_format/{year}/Daily_AcqTime_{comp}_{year}_{month}.tif'\n",
    "\n",
    "S2_file = [file for file in getFilelist(s2_pathbase, 'vrt', deep=True) if 'S2' in file][0]\n",
    "# warp datasets needed for calculations to the spatial extent of the sharpened LST\n",
    "LST_acq_spatial_sub = warp_raster_to_reference(source_path=LST_acq_file, reference_path=S2_file, output_path='MEM', resampling='near')\n",
    "dem_sub = warp_raster_to_reference(source_path=dem_path, reference_path=S2_file, output_path='MEM', resampling='bilinear')\n",
    "slope_sub  = warp_raster_to_reference(source_path=slope_path, reference_path=S2_file, output_path='MEM', resampling='bilinear')\n",
    "aspect_sub = warp_raster_to_reference(source_path=aspect_path, reference_path=S2_file, output_path='MEM', resampling='bilinear')\n",
    "lat_sub = warp_raster_to_reference(source_path=lat_path, reference_path=S2_file, output_path='MEM', resampling='bilinear')\n",
    "lon_sub = warp_raster_to_reference(source_path=lon_path, reference_path=S2_file, output_path='MEM', resampling='bilinear')\n",
    "geopot_sub = warp_raster_to_reference(source_path=geopot_path, reference_path=S2_file, output_path='MEM', resampling='bilinear')\n",
    "\n",
    "slope_path = slope_sub\n",
    "aspect_path = aspect_sub\n",
    "dem_path = dem_sub\n",
    "lat_path = lat_sub\n",
    "lon_path = lon_sub\n",
    "\n",
    "era_ds = warp_ERA5_to_reference(grib_path=file, reference_path=LST_acq_spatial_sub)\n",
    "bandNumber = era_ds.RasterCount\n",
    "era_time = [pd.Timestamp(era_ds.GetRasterBand(i+1).GetDescription()) for i in range(bandNumber)]\n",
    "\n",
    "# open and load the acquisition raster from LST\n",
    "LST_acq_ds = checkPath(LST_acq_spatial_sub)\n",
    "arr = LST_acq_ds.GetRasterBand(doy).ReadAsArray()\n",
    "arr = arr.astype(np.int64)\n",
    "arr_flat = arr.ravel()\n",
    "arr_ts = pd.to_datetime(arr_flat, unit='s')\n",
    "arr_up = pd.Series(arr_ts).dt.ceil('h')\n",
    "arr_up = arr_up.values.reshape(arr.shape)\n",
    "arr_min = pd.Series(arr_ts).dt.minute\n",
    "arr_min = arr_min.values.reshape(arr.shape)\n",
    "\n",
    "# get the relevant bands of era5 dataset (i.e. those bands, that reflect the upper and lower )\n",
    "bands = []\n",
    "for d1 in np.unique(arr_up):\n",
    "     for count, e5 in enumerate(era_time):\n",
    "          if d1 == e5:\n",
    "               bands.append(count)\n",
    "# load the era5 variable acquisition-wise into 2D numpy array \n",
    "# load the era5 variable acquisition-wise into 2D numpy array \n",
    "arrL = []\n",
    "for b in bands: \n",
    "     # compare the time of LST composite with \n",
    "     mask = arr_up == era_time[b]\n",
    "     # load the band that holds the observation just after LST acquisition\n",
    "     after = era_ds.GetRasterBand(b).ReadAsArray()\n",
    "     # load the band that holds the observation just prior to LST acquisition\n",
    "     before = era_ds.GetRasterBand(b-1).ReadAsArray()\n",
    "     # calculate the linearly interpolated values at the minute of acquisition\n",
    "     vals_interpolated = before - (before - after) * (np.array(arr_min, dtype=np.float16) / 60) # in J/m²\n",
    "     # convert to W/m²\n",
    "     vals_watt = vals_interpolated /3600\n",
    "     arrL.append(vals_watt * mask)\n",
    "block = np.dstack(arrL)\n",
    "\n",
    "block[block == 0] = np.nan\n",
    "ssrd_watt = np.nanmax(block, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mask of the nan values, as the output of pvlib.irradiance.get_total_irradiance does skip them which hinders rebuild to 2D\n",
    "valid_mask = np.isfinite(ssrd_watt)\n",
    "arr_ts_masked = arr_ts[valid_mask.ravel()]\n",
    "\n",
    "# load slope, aspect, lat, lon, dem\n",
    "ds = checkPath(slope_path)\n",
    "slope = ds.GetRasterBand(1).ReadAsArray()\n",
    "slope_flat = slope.ravel()\n",
    "slope_flat_masked = slope_flat[valid_mask.ravel()]\n",
    "\n",
    "ds = checkPath(aspect_path)\n",
    "aspect = ds.GetRasterBand(1).ReadAsArray()\n",
    "aspect_flat = aspect.ravel()\n",
    "aspect_flat_masked = aspect_flat[valid_mask.ravel()]\n",
    "\n",
    "ds = checkPath(dem_path)\n",
    "dem = ds.GetRasterBand(1).ReadAsArray()\n",
    "dem_flat = dem.ravel()\n",
    "dem_flat_masked = dem_flat[valid_mask.ravel()]\n",
    "\n",
    "ds = checkPath(lat_path)\n",
    "lat = ds.GetRasterBand(1).ReadAsArray()\n",
    "lat_flat = lat.ravel()\n",
    "lat_flat_masked = lat_flat[valid_mask.ravel()]\n",
    "\n",
    "ds = checkPath(lon_path)\n",
    "lon = ds.GetRasterBand(1).ReadAsArray()\n",
    "lon_flat = lon.ravel()\n",
    "lon_flat_masked = lon_flat[valid_mask.ravel()]\n",
    "\n",
    "# get solar viewing conditions for acquisition time\n",
    "solpos = solarposition.get_solarposition(\n",
    "    time=arr_ts_masked,       # vector of timestamps\n",
    "    latitude=lat_flat_masked, # vector of latitudes (same length as time or broadcastable)\n",
    "    longitude=lon_flat_masked,\n",
    "    altitude=dem_flat_masked\n",
    ")\n",
    "\n",
    "# calculate extraterrestrial radiation (horizontal)\n",
    "dni_extra = pvlib.irradiance.get_extra_radiation(arr_ts_masked)\n",
    "\n",
    "# Compute clearness index\n",
    "ssrd_watt_flat = ssrd_watt.ravel()\n",
    "ssrd_watt_flat_masked = ssrd_watt_flat[valid_mask.ravel()]\n",
    "ghi = ssrd_watt_flat_masked\n",
    "# cos_zenith = np.cos(np.radians(solpos['zenith'].values[0]))\n",
    "# ghi_clear = dni_extra.values[0] * cos_zenith\n",
    "# kt = ghi / ghi_clear\n",
    "\n",
    "\n",
    "# Decompose GHI to DNI and DHI using Erbs model\n",
    "dni_dhi = pvlib.irradiance.erbs(ghi, solpos['zenith'], e5)\n",
    "dni, dhi = dni_dhi['dni'], dni_dhi['dhi']\n",
    "\n",
    "\n",
    "# compute radiation on the tilted terrain\n",
    "\n",
    "irradiance_tilted = get_total_irradiance(\n",
    "    surface_tilt=slope_flat_masked,\n",
    "    surface_azimuth=aspect_flat_masked,\n",
    "    dni=dni,\n",
    "    ghi=ghi,\n",
    "    dhi=dhi,\n",
    "    solar_zenith=solpos['zenith'],\n",
    "    solar_azimuth=solpos['azimuth']\n",
    ")\n",
    "\n",
    "# bring back to 2D\n",
    "poa_global_arr = np.full(slope.shape, np.nan)\n",
    "poa_global_arr[valid_mask] = irradiance_tilted['poa_global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5e6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-26 05:00:00    77.952660\n",
      "2019-07-26 05:00:00    77.952489\n",
      "2019-07-26 05:00:00    77.952317\n",
      "2019-07-26 05:00:00    77.952145\n",
      "2019-07-26 05:00:00    77.951974\n",
      "                         ...    \n",
      "2019-07-26 05:00:00    77.776048\n",
      "2019-07-26 05:00:00    77.775877\n",
      "2019-07-26 05:00:00    77.775705\n",
      "2019-07-26 05:00:00    77.775535\n",
      "2019-07-26 05:00:00    77.775363\n",
      "Name: zenith, Length: 2250000, dtype: float64\n",
      "[[6.319133  6.3197    6.3202662 ... 7.16779   7.1683908 7.1689925]\n",
      " [6.318756  6.3193226 6.3198895 ... 7.167408  7.168009  7.1686106]\n",
      " [6.318379  6.3189454 6.3195124 ... 7.167026  7.167627  7.1682286]\n",
      " ...\n",
      " [5.770111  5.7706685 5.7712255 ... 6.6026177 6.6031933 6.603769 ]\n",
      " [5.769769  5.7703266 5.770883  ... 6.60225   6.602825  6.6034007]\n",
      " [5.769428  5.7699842 5.7705417 ... 6.6018815 6.602457  6.603032 ]]\n",
      "2019-07-26 05:00:00\n",
      "[0.06233883 0.06234828 0.0623577  ... 0.06611559 0.0661253  0.06613498]\n",
      "2019-07-26 06:00:00    69.093295\n",
      "2019-07-26 06:00:00    69.093117\n",
      "2019-07-26 06:00:00    69.092939\n",
      "2019-07-26 06:00:00    69.092759\n",
      "2019-07-26 06:00:00    69.092581\n",
      "                         ...    \n",
      "2019-07-26 06:00:00    68.853232\n",
      "2019-07-26 06:00:00    68.853054\n",
      "2019-07-26 06:00:00    68.852875\n",
      "2019-07-26 06:00:00    68.852697\n",
      "2019-07-26 06:00:00    68.852518\n",
      "Name: zenith, Length: 2250000, dtype: float64\n",
      "[[80.77515  80.77688  80.7786   ... 83.3333   83.335045 83.3368  ]\n",
      " [80.77414  80.77587  80.777596 ... 83.33236  83.33411  83.33586 ]\n",
      " [80.773125 80.77485  80.77658  ... 83.33141  83.33317  83.334915]\n",
      " ...\n",
      " [79.2799   79.28175  79.2836   ... 81.945984 81.947685 81.94939 ]\n",
      " [79.27893  79.280785 79.28263  ... 81.945076 81.94678  81.94848 ]\n",
      " [79.27797  79.279816 79.28167  ... 81.94418  81.945885 81.947586]]\n",
      "2019-07-26 06:00:00\n",
      "[3.4846702  3.48476296 3.48485484 ... 3.50881811 3.50890744 3.50899638]\n"
     ]
    }
   ],
   "source": [
    "meanL = []\n",
    "for count, e5 in enumerate(era_time):\n",
    "    if e5.day == doy:\n",
    "        ssrd_hour = era_ds.GetRasterBand(count).ReadAsArray()\n",
    "        if np.sum(ssrd_hour) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if count > 606:\n",
    "                break\n",
    "            time_hour = np.full((2250000,), e5)\n",
    "            # get solar viewing conditions for acquisition time\n",
    "            \n",
    "            solpos = solarposition.get_solarposition(\n",
    "                time=time_hour,       # vector of timestamps\n",
    "                latitude=lat_flat_masked, # vector of latitudes (same length as time or broadcastable)\n",
    "                longitude=lon_flat_masked,\n",
    "                altitude=dem_flat_masked\n",
    "            )\n",
    "\n",
    "            print(solpos['zenith'])\n",
    "            # Compute clearness index\n",
    "            ghi = ssrd_hour / 3600\n",
    "            print(ghi)\n",
    "            print(e5)\n",
    "            # Decompose GHI to DNI and DHI using Erbs model\n",
    "            dni_dhi = pvlib.irradiance.erbs(ghi.ravel(), solpos['zenith'], e5)\n",
    "            dni, dhi = dni_dhi['dni'], dni_dhi['dhi']\n",
    "            print(dni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5c1b844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solpos['zenith'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9cf3bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slope_flat_masked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m irradiance_tilted = get_total_irradiance(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     surface_tilt=\u001b[43mslope_flat_masked\u001b[49m,\n\u001b[32m      3\u001b[39m     surface_azimuth=aspect_flat_masked,\n\u001b[32m      4\u001b[39m     dni=dni,\n\u001b[32m      5\u001b[39m     ghi=ghi.ravel(),\n\u001b[32m      6\u001b[39m     dhi=dhi,\n\u001b[32m      7\u001b[39m     solar_zenith=solpos[\u001b[33m'\u001b[39m\u001b[33mzenith\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      8\u001b[39m     solar_azimuth=solpos[\u001b[33m'\u001b[39m\u001b[33mazimuth\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'slope_flat_masked' is not defined"
     ]
    }
   ],
   "source": [
    "irradiance_tilted = get_total_irradiance(\n",
    "    surface_tilt=slope_flat_masked,\n",
    "    surface_azimuth=aspect_flat_masked,\n",
    "    dni=dni,\n",
    "    ghi=ghi.ravel(),\n",
    "    dhi=dhi,\n",
    "    solar_zenith=solpos['zenith'],\n",
    "    solar_azimuth=solpos['azimuth']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variable = 'geopotential'\n",
    "    # for year in range(2017, 2025, 1):\n",
    "year = 2019\n",
    "files = [file for file in getFilelist(os.path.join(base_path, variable), '.grib') if str(year) in file]\n",
    "        # for file in files:\n",
    "file = files[5]\n",
    "arr = stackReader(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99460894",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(arr, axis=2, return_counts=True)\n",
    "if len(counts) == 1:\n",
    "    print(f'{variable} contains only a single value in year {year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in variables:\n",
    "    for year in range(2017, 2025, 1):\n",
    "        files = [file for file in getFilelist(os.path.join(base_path, variable), '.grib') if str(year) in file]\n",
    "        for file in files:\n",
    "            arr = stackReader(file)\n",
    "            _, counts = np.unique(arr, axis=2, return_counts=True)\n",
    "            if len(counts) == 1:\n",
    "                print(f'{variable} contains only a single value in year {year} and month {INT_TO_MONTH[f'{int(file.split('_')[-1].split('.')[0]):02d}']}')\n",
    "            else:\n",
    "                print(f'{variable} contains mucho data in year {year} and month {INT_TO_MONTH[f'{int(file.split('_')[-1].split('.')[0]):02d}']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5f188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cds_era5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

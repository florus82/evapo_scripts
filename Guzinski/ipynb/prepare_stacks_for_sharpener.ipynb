{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1af8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51584fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year \n",
    "year = 2019\n",
    "\n",
    "# stat used for compositing\n",
    "comp_stat = 'minVZA'\n",
    "# paths\n",
    "path_to_S2_tiles = f'/data/Aldhani/eoagritwin/force/output/Guzinski/{year}/'\n",
    "path_to_slope = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/SLOPE/'\n",
    "path_to_aspect = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/ASPECT/'\n",
    "path_to_incident = f'/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/INCIDENCE/{comp_stat}/{year}/'\n",
    "\n",
    "path_to_LST = f'/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/{comp_stat}/{year}/'\n",
    "temp_dump = '/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b85f606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All FORCE files outside April-October deleted\n"
     ]
    }
   ],
   "source": [
    "####### general FORCE clean-up\n",
    "# first, all files for months outside of studay aim will be deleted to save storgage\n",
    "reduce_forceTSI_output_to_validmonths(f'{path_to_S2_tiles}/tiles', 4, 10)\n",
    "print('All FORCE files outside April-October deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "625680b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 146 tiles available for processing for the year 2019\n",
      "all dates of composites are the same :)\n"
     ]
    }
   ],
   "source": [
    "###### which tiles should be processed\n",
    "# get a list with all available tiles\n",
    "files = getFilelist(f'{path_to_S2_tiles}/tiles', '.tif', deep=True) \n",
    "unique_tiles = get_forceTSI_output_Tiles(files)\n",
    "print(f'There are {len(unique_tiles)} tiles available for processing for the year {year}')\n",
    "# check if all tiles contain composites for the same dates and export the dates as list. This list will\n",
    "# be used to identiy LST scenes that relate to S2 scenes\n",
    "files = [file for file in files if any(tile in file for tile in tiles_to_process)]\n",
    "date_list = check_forceTSI_compositionDates(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6687679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all highRes datasets: S2 composites, aspect, ratio and incedence for the tile/time and stack them (in a composite if more than one tile is processed)\n",
    "\n",
    "# set the highRes S2 tiles that will be processed\n",
    "tiles_to_process = createFORCEtileLIST([58, 59, 58, 59],\n",
    "                                       [33, 34, 34, 34])\n",
    "\n",
    "# tiles_to_process = createFORCEtileLIST([63, 64, 63, 64],\n",
    "#                                        [43, 43, 44, 44])\n",
    "\n",
    "# slope-tiles\n",
    "slopes = [file for file in getFilelist(path_to_slope, '.tif') if any(tile in file for tile in tiles_to_process)] # if any tile name is in file\n",
    "# aspect-tiles\n",
    "aspects = [file for file in getFilelist(path_to_aspect, '.tif') if any(tile in file for tile in tiles_to_process)] # if any tile name is in file\n",
    "\n",
    "# get those tiles (and composite if more than one tile is provided)\n",
    "if len(tiles_to_process) == 1:\n",
    "    \n",
    "    slope_path = slopes[0]\n",
    "    aspect_path = aspects[0]\n",
    "\n",
    "else:\n",
    "    slope_path = f'{temp_dump}SLOPE.vrt'\n",
    "    gdal.BuildVRT(slope_path, slopes)\n",
    "\n",
    "    aspect_path = f'{temp_dump}ASPECT.vrt'\n",
    "    gdal.BuildVRT(aspect_path, aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd97d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_0.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_1.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_2.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_3.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_4.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_5.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_6.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_7.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/S2_Test/Force_X_from_58_to_59_Y_from_33_to_34/Force_X_from_58_to_59_Y_from_33_to_34_8.vrt\n",
      "single vrts created\n",
      "paths in vrts made relative\n",
      "overlord vrt created\n"
     ]
    }
   ],
   "source": [
    "#### S2 composites are time sensitive (need to be aligned with date of LST observation), so is incidence\n",
    "\n",
    "# for date in date_list:\n",
    "date = date_list[0] # will be replaced through loop\n",
    "\n",
    "\n",
    "# get those tiles (and composite if more than one tile is provided)\n",
    "if len(tiles_to_process) == 1:\n",
    "\n",
    "    tilesS2 = [file for file in getFilelist(path_to_S2_tiles, '.tif', deep=True) if tiles_to_process[0] in file and f'{date}.tif' in file]\n",
    "    S2_path = f'{temp_dump}S2.vrt'\n",
    "    gdal.BuildVRT(S2_path, tilesS2)\n",
    "\n",
    "else:\n",
    "    tilesS2 = [file for file in getFilelist(path_to_S2_tiles, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and f'{date}.tif' in file] \n",
    "    force_to_vrt(tilesS2,\n",
    "             getCOLORSinOrderFORCELIST(tilesS2, list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)), single=False),\n",
    "             f'{temp_dump}S2_Test',\n",
    "             pyramids=False, \n",
    "             bandnames=list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)))\n",
    "    S2_path = [file for file in getFilelist(f'{temp_dump}S2_Test', '.vrt', deep=True) if '_Cube' in file][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de5129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_NIR_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_NIR_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_NIR_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_BLU_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_BLU_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_BLU_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_SW1_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_SW1_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_SW1_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_RE1_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RE1_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RE1_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_SW2_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_SW2_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_SW2_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_RE3_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RE3_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RE3_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_RED_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RED_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RED_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_RE2_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RE2_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_RE2_TSI_20190406.tif']\n",
      "['/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0033/20181201-20200131_001-365_HL_TSA_SEN2L_GRN_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0058_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_GRN_TSI_20190406.tif', '/data/Aldhani/eoagritwin/force/output/Guzinski/2019/tiles/X0059_Y0034/20181201-20200131_001-365_HL_TSA_SEN2L_GRN_TSI_20190406.tif']\n"
     ]
    }
   ],
   "source": [
    "date = date_list[0]\n",
    "tilesS2 = [file for file in getFilelist(path_to_S2_tiles, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and f'{date}.tif' in file]\n",
    "aa = getCOLORSinOrderFORCELIST(tilesS2, list(set([tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2])), single=False)\n",
    "for a in aa:print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3626ec3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NIR', 'BLU', 'SW1', 'RE1', 'SW2', 'RE3', 'RED', 'RE2', 'GRN']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765655d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine LST and incidence files associated with respective S2 composite\n",
    "band_dict = transform_compositeDate_into_LSTbands(date, 4)\n",
    "\n",
    "# get all LST bands that can be sharped with the S2 composite at this date (and sun angle incidence files as well, as they are dependent on that date\n",
    "incid_dates = []\n",
    "LSTs = []\n",
    "\n",
    "for k, v in band_dict.items():\n",
    "       month = v['month']\n",
    "       band = int(v['band'])\n",
    "       v_path = f'{path_to_LST}Daily_LST_{comp_stat}_{year}_{month}.tif'\n",
    "       ds = gdal.Open(v_path, 0)\n",
    "       LST_arr = ds.GetRasterBand(band).ReadAsArray() # store as single Tiff in temp\n",
    "       makeTif_np_to_matching_tif(LST_arr, v_path, f'{temp_dump}Daily_LST_{comp_stat}_{year}_{month}_{band:02d}.tif')\n",
    "\n",
    "       # store the paths for selecting incidence for corresponding LST\n",
    "       incid_dates.append(f'{year}_{month}_{band:02d}.tif')\n",
    "       LSTs.append(f'{temp_dump}Daily_LST_{comp_stat}_{year}_{month}_{band:02d}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### loop over the LST files and go\n",
    "\n",
    "for idx, LST_file in enumerate(LSTs):\n",
    "    if idx != 0:\n",
    "        break\n",
    "    # incidence-tiles\n",
    "    incids = [file for file in getFilelist(path_to_incident, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and incid_dates[idx] in file] \n",
    "    \n",
    "    # get those tiles (and composite if more than one tile is provided)\n",
    "    if len(tiles_to_process) == 1:\n",
    "        incid_path = incids[0]\n",
    "\n",
    "    else:\n",
    "        incid_path = f'{temp_dump}INCIDENCE.vrt'\n",
    "        gdal.BuildVRT(incid_path, incids)\n",
    "\n",
    "    # sanity check for incidence and LST date\n",
    "    if (LSTs[idx].split(f'{year}')[-1] == incids[0].split(f'{year}')[-1]):\n",
    "        \n",
    "        # get LST file\n",
    "        lowRes_path = LSTs[idx]\n",
    "        # create highRes file through exapnding the vrt of S2\n",
    "        highRes_path = f'{temp_dump}HIGHRES.vrt'\n",
    "        gdal.BuildVRT(highRes_path, [S2_path, slope_path, aspect_path, incid_path], separate=True)\n",
    "    else:\n",
    "        raise ValueError('Something is seriously wrong with the alignment of LST and incidence dates!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_repos.pyDMS.pyDMS.pyDMS import *\n",
    "import time\n",
    "for i in range(20,25,5):\n",
    "    movWin = i\n",
    "    highResFilename = highRes_path\n",
    "    lowResFilename = lowRes_path\n",
    "    outputFilename = f'{temp_dump}sharp_{movWin}_incl_incidence_bad.tif'\n",
    "\n",
    "\n",
    "    useDecisionTree = False\n",
    "\n",
    "    commonOpts = {\"highResFiles\":               [highResFilename],\n",
    "                    \"lowResFiles\":              [lowResFilename],\n",
    "                    \"lowResQualityFiles\":         [],# [lowResMaskFilename],\n",
    "                    \"lowResGoodQualityFlags\":     [],#[255],\n",
    "                    \"cvHomogeneityThreshold\":     25,\n",
    "                    \"movingWindowSize\":           movWin,\n",
    "                    \"disaggregatingTemperature\":  True}\n",
    "    dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                    \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "    sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                    'activation':                 'tanh'}\n",
    "    nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                    \"regressorOpt\":               sknnOpts}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if useDecisionTree:\n",
    "        opts = commonOpts.copy()\n",
    "        opts.update(dtOpts)\n",
    "        disaggregator = DecisionTreeSharpener(**opts)\n",
    "    else:\n",
    "        opts = commonOpts.copy()\n",
    "        opts.update(nnOpts)\n",
    "        disaggregator = NeuralNetworkSharpener(**opts)\n",
    "\n",
    "    print(\"Training regressor...\")\n",
    "    disaggregator.trainSharpener()\n",
    "    print(\"Sharpening...\")\n",
    "    downscaledFile = disaggregator.applySharpener(highResFilename, lowResFilename)\n",
    "    print(\"Residual analysis...\")\n",
    "    residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                                # lowResMaskFilename,\n",
    "                                                                    doCorrection=True)\n",
    "    print(\"Saving output...\")\n",
    "    highResFile = gdal.Open(highResFilename)\n",
    "    if correctedImage is not None:\n",
    "        outImage = correctedImage\n",
    "    else:\n",
    "        outImage = downscaledFile\n",
    "    # outData = utils.binomialSmoother(outData)\n",
    "    outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                            outImage.GetGeoTransform(),\n",
    "                            outImage.GetProjection(),\n",
    "                            outputFilename)\n",
    "    residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                                residualImage.GetGeoTransform(),\n",
    "                                residualImage.GetProjection(),\n",
    "                                os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                                os.path.splitext(outputFilename)[1])\n",
    "\n",
    "    outFile = None\n",
    "    residualFile = None\n",
    "    downsaceldFile = None\n",
    "    highResFile = None\n",
    "\n",
    "    print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6673c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51584fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/users/potzschf/conda/envs/workhorse/lib/python3.12/site-packages/osgeo/gdal.py:311: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import * \n",
    "from other_repos.pyDMS.pyDMS.pyDMS import *\n",
    "import time\n",
    "\n",
    "os.environ[\"GDAL_MAX_DATASET_POOL_SIZE\"] = \"600\"\n",
    "# get tiles for Brandenburg\n",
    "# bran = pd.read_csv('/data/Aldhani/eoagritwin/misc/state_tile_csv/clipped_grid_bran_tiles.csv')\n",
    "\n",
    "# paths\n",
    "lowmask_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/reprojected/THUENEN_GER_LST_WARP.tif'\n",
    "temp_dump = '/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/'\n",
    "\n",
    "# create vrts of slope, aspect and landcover (for masking)\n",
    "path_to_slope = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/SLOPE/'\n",
    "path_to_aspect = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/ASPECT/'\n",
    "path_to_agro = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/THUENEN_2021/'\n",
    "\n",
    "# get all highRes datasets: S2 composites, aspect, ratio and incedence for the tile/time and stack them (in a composite if more than one tile is processed)\n",
    "# set the highRes S2 tiles that will be processed\n",
    "# tiles_to_process = createFORCEtileLIST(list(bran['Tile_X']),\n",
    "#                                         list(bran['Tile_Y']))\n",
    "\n",
    "Tile_X = [63,64,63,64]\n",
    "Tile_Y = [41,41,42,42]\n",
    "\n",
    "tiles_to_process = createFORCEtileLIST(Tile_X, Tile_Y)\n",
    "\n",
    "# make a specific folder for this run and store the info together\n",
    "csv_path = f'{temp_dump}folders.csv'\n",
    "rand_foldname = getUniqueIDfromTILESXY(Tile_X, Tile_Y)\n",
    "temp_dump_fold = f'{temp_dump}{rand_foldname}/'\n",
    "\n",
    "if not os.path.exists(temp_dump_fold):\n",
    "    os.makedirs(temp_dump_fold,exist_ok=False)\n",
    "    df = pd.DataFrame({\n",
    "            'Folder': temp_dump_fold,\n",
    "            'Tile_X': Tile_X,\n",
    "            'Tile_Y': Tile_Y   \n",
    "        })\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        df.to_csv(csv_path, index=False)\n",
    "    else:\n",
    "        df_exist = pd.read_csv(csv_path)\n",
    "        df_new = pd.concat([df_exist, df], ignore_index=True)\n",
    "        df_new.to_csv(csv_path, index=False)\n",
    "        # add the lines\n",
    "\n",
    "    # slope-tiles\n",
    "    slopes = [file for file in getFilelist(path_to_slope, '.tif') if any(tile in file for tile in tiles_to_process)] # if any tile name is in file\n",
    "    # aspect-tiles\n",
    "    aspects = [file for file in getFilelist(path_to_aspect, '.tif') if any(tile in file for tile in tiles_to_process)] # if any tile name is in file\n",
    "    # thuenen-tiles\n",
    "    thuenen = [file for file in getFilelist(path_to_agro, '.tif') if any(tile in file for tile in tiles_to_process)] # if any tile name is in file\n",
    "\n",
    "    # get those tiles (and composite if more than one tile is provided)\n",
    "    if len(tiles_to_process) == 1:\n",
    "        \n",
    "        slope_path = slopes[0]\n",
    "        aspect_path = aspects[0]\n",
    "        thuenen_path = thuenen[0]\n",
    "\n",
    "    else:\n",
    "        slope_path = f'{temp_dump_fold}SLOPE_vrt'\n",
    "        gdal.BuildVRT(slope_path, slopes)\n",
    "\n",
    "        aspect_path = f'{temp_dump_fold}ASPECT.vrt'\n",
    "        gdal.BuildVRT(aspect_path, aspects)\n",
    "\n",
    "        thuenen_path = f'{temp_dump_fold}THUENEN.vrt'\n",
    "        gdal.BuildVRT(thuenen_path, thuenen)\n",
    "else:\n",
    "    raise ValueError(f'{temp_dump_fold} already exists!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189c636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dates of composites are the same :)\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_0.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_1.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_2.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_3.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_4.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_5.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_6.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_7.vrt\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/S2_20190705/Force_X_from_63_to_64_Y_from_41_to_42/Force_X_from_63_to_64_Y_from_41_to_42_8.vrt\n",
      "single vrts created\n",
      "paths in vrts made relative\n",
      "overlord vrt created\n",
      "['BLU', 'GRN', 'NIR', 'RE1', 'RE2', 'RE3', 'RED', 'SW1', 'SW2']\n"
     ]
    }
   ],
   "source": [
    "# year \n",
    "year = 2019#range(2017,2025):\n",
    "  \n",
    "# paths\n",
    "path_to_S2_tiles = f'/data/Aldhani/eoagritwin/force/output/Guzinski/{year}/'\n",
    "\n",
    "##### which tiles should be processed\n",
    "# get a list with all available tiles\n",
    "files = getFilelist(f'{path_to_S2_tiles}/tiles', '.tif', deep=True) \n",
    "files = [file for file in files if any(tile in file for tile in tiles_to_process)]\n",
    "date_list = check_forceTSI_compositionDates(files)\n",
    "\n",
    "th_ds = gdal.Open(thuenen_path)\n",
    "th_arr = th_ds.GetRasterBand(1).ReadAsArray()\n",
    "mask = np.where(th_arr == -9999, 0, 1)\n",
    "\n",
    "lowRes_files = []\n",
    "highRes_files = []\n",
    "highRes_names = []\n",
    "#### S2 composites are time sensitive (need to be aligned with date of LST observation), so is incidence\n",
    "for date in date_list:\n",
    "\n",
    "    # if not os.path.exists(f'{temp_dump_fold}INCIDENCE_{date}.vrt'):\n",
    "    if date != '20190705':\n",
    "        continue\n",
    "    # get those tiles (and composite if more than one tile is provided)\n",
    "    if len(tiles_to_process) == 1:\n",
    "\n",
    "        tilesS2 = [file for file in getFilelist(path_to_S2_tiles, '.tif', deep=True) if tiles_to_process[0] in file and f'{date}.tif' in file]\n",
    "        S2_path = f'{temp_dump_fold}S2_{date}.vrt'\n",
    "        gdal.BuildVRT(S2_path, tilesS2)\n",
    "\n",
    "    else:\n",
    "        tilesS2 = [file for file in getFilelist(path_to_S2_tiles, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and f'{date}.tif' in file] \n",
    "        force_to_vrt(tilesS2,\n",
    "                getCOLORSinOrderFORCELIST(tilesS2, list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)), single=False),\n",
    "                f'{temp_dump_fold}S2_{date}',\n",
    "                False,\n",
    "                bandnames= list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)))\n",
    "        print(list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)))\n",
    "        S2_path = [file for file in getFilelist(f'{temp_dump_fold}S2_{date}', '.vrt', deep=True) if '_Cube' in file][0]\n",
    "        \n",
    "        # determine LST and incidence files associated with respective S2 composite\n",
    "    band_dict = transform_compositeDate_into_LSTbands(date, 4)\n",
    "\n",
    "\n",
    "    # stat used for compositing\n",
    "    for comp_stat in ['minVZA', 'maxLST']:\n",
    "        path_to_incident = f'/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/INCIDENCE/{comp_stat}/{year}/'\n",
    "        path_to_LST = f'/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/{comp_stat}/{year}/'\n",
    "\n",
    "        # get all LST bands that can be sharped with the S2 composite at this date (and sun angle incidence files as well, as they are dependent on that date\n",
    "        LSTs = []\n",
    "\n",
    "        for k, v in band_dict.items():\n",
    "            month = v['month']\n",
    "            band = int(v['band'])\n",
    "            v_path = f'{path_to_LST}Daily_LST_{comp_stat}_{year}_{month}.tif'\n",
    "            ds = gdal.Open(v_path, 0)\n",
    "            LST_arr = ds.GetRasterBand(band).ReadAsArray() # store as single Tiff in temp\n",
    "            makeTif_np_to_matching_tif(LST_arr, v_path, f'{temp_dump_fold}Daily_LST_{comp_stat}_{year}_{month}_{band:02d}.tif')\n",
    "\n",
    "            # store the paths for selecting incidence for corresponding LST\n",
    "            incid_date = f'{year}_{month}_{band:02d}.tif'\n",
    "            lowRes_files.append(f'{temp_dump_fold}Daily_LST_{comp_stat}_{year}_{month}_{band:02d}.tif')\n",
    "\n",
    "            # incidence-tiles\n",
    "            incids = [file for file in getFilelist(path_to_incident, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and incid_date in file] \n",
    "            # get those tiles (and composite if more than one tile is provided)\n",
    "            if len(tiles_to_process) == 1:\n",
    "                incid_path = incids[0]\n",
    "\n",
    "            else:\n",
    "                incid_path = f'{temp_dump_fold}INCIDENCE_{comp_stat}_{incid_date.split('.')[0]}.vrt'\n",
    "                gdal.BuildVRT(incid_path, incids)\n",
    "\n",
    "            # create highRes file through exapnding the vrt of S2\n",
    "            highRes_path = f'{temp_dump_fold}HIGHRES_{comp_stat}_{incid_date.split('.')[0]}.vrt'\n",
    "            gdal.BuildVRT(highRes_path, [S2_path, slope_path, aspect_path, incid_path], separate=True)\n",
    "            highRes_files.append(highRes_path)\n",
    "            highRes_names.append('S2notMasked')\n",
    "            maskVRT(highRes_path, mask)\n",
    "            highRes_files.append(f'{temp_dump_fold}HIGHRES_{comp_stat}_{incid_date}')\n",
    "            lowRes_files.append(f'{temp_dump_fold}Daily_LST_{comp_stat}_{year}_{month}_{band:02d}.tif')\n",
    "            highRes_names.append('S2Masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6220fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblist = []\n",
    "outFolder = f'/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/sharpened/{rand_foldname}/'\n",
    "for idx, highResFilename in enumerate(highRes_files):\n",
    "    lowResFilename = lowRes_files[idx]\n",
    "    f1 = f'{outFolder}{'/'.join(highResFilename.split('.')[0].split('_')[2:6])}/'\n",
    "    for maskname, mask_lowRes in zip(['withoutLSTmask', 'withLSTmask'], ['', lowmask_path]):\n",
    "        lowResMaskFilename = mask_lowRes\n",
    "        f2 = f'{f1}{maskname}/'\n",
    "        for movWin in range(15,60,10):\n",
    "            for cv in range(5,55,10):\n",
    "                for regrat in [0.1, 0.2, 0.3]:\n",
    "                    kombi = f'mvwin{movWin}_cv{cv}_regrat{int(regrat*100):02d}_{highRes_names[idx]}_{maskname}'\n",
    "                    f3 = f'{f2}{highRes_names[idx]}/'\n",
    "                    os.makedirs(f3, exist_ok=True)\n",
    "                    os.makedirs(f'{f3}residuals/', exist_ok=True)\n",
    "                    joblist.append([highResFilename, \n",
    "                                lowResFilename,\n",
    "                                mask_lowRes,\n",
    "                                cv, movWin, regrat,\n",
    "                                f'{f3}{'_'.join(highResFilename.split('.')[0].split('_')[2:6])}_{kombi}.tif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3172a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFilename = joblist[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e5f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/sharpened/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/minVZA/2019/July/01/withoutLSTmask/S2notMasked/Values/minVZA_2019_July_01_mvwin15_cv5_regrat10_S2notMasked_withoutLSTmask.tif\n",
      "/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/sharpened/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/minVZA/2019/July/01/withoutLSTmask/S2notMasked/residuals/minVZA_2019_July_01_mvwin15_cv5_regrat10_S2notMasked_withoutLSTmask.tif_residual.tif\n"
     ]
    }
   ],
   "source": [
    "print(f'{os.path.split(outputFilename)[0]}/Values/{os.path.split(outputFilename)[1]}')\n",
    "print(f'{os.path.split(outputFilename)[0]}/residuals/{os.path.split(outputFilename)[1]}_residual{os.path.splitext(outputFilename)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for idx, LST_file in enumerate(LSTs):\n",
    "            # incidence-tiles\n",
    "            incids = [file for file in getFilelist(path_to_incident, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and incid_dates[idx] in file] \n",
    "            # get those tiles (and composite if more than one tile is provided)\n",
    "            if len(tiles_to_process) == 1:\n",
    "                incid_path = incids[0]\n",
    "\n",
    "            else:\n",
    "                incid_path = f'{temp_dump_fold}INCIDENCE_{comp_stat}_{incid_dates[idx]}.vrt'\n",
    "                gdal.BuildVRT(incid_path, incids)\n",
    "\n",
    "            # sanity check for incidence and LST date\n",
    "            if (LSTs[idx].split(f'{year}')[-1] == incids[0].split(f'{year}')[-1]):\n",
    "                \n",
    "                # get LST file\n",
    "                lowRes_files.append(LSTs[idx])\n",
    "                # create highRes file through exapnding the vrt of S2\n",
    "                highRes_path = f'{temp_dump_fold}HIGHRES_{comp_stat}_{incid_dates[idx]}.vrt'\n",
    "                gdal.BuildVRT(highRes_path, [S2_path, slope_path, aspect_path, incid_path], separate=True)\n",
    "                maskVRT(highRes_path, mask)\n",
    "                highRes_files.append(f'{temp_dump_fold}HIGHRES_{comp_stat}_{incid_dates[idx]}.tif')\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Something is seriously wrong with the alignment of LST and incidence dates!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/sharpened/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb77909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = getFilelist('/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/sharpened/2514b73c638b86ba52047c6c65eea221652398b499d492380209a557c938f1ba/', '.tif') #temp_dump_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e91efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [file.split('/')[-1] for file in files if not 'residual' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e6ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in fnames:\n",
    "    if file.split('_')[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

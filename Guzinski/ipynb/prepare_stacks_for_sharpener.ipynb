{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51584fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import * \n",
    "from other_repos.pyDMS.pyDMS.pyDMS import *\n",
    "import time\n",
    "\n",
    "os.environ[\"GDAL_MAX_DATASET_POOL_SIZE\"] = \"600\"\n",
    "# get tiles for Brandenburg\n",
    "bran = pd.read_csv('/data/Aldhani/eoagritwin/misc/state_tile_csv/clipped_grid_bran_tiles.csv')\n",
    "\n",
    "# create vrts of slope and aspect\n",
    "path_to_slope = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/SLOPE/'\n",
    "path_to_aspect = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/ASPECT/'\n",
    "temp_dump = '/data/Aldhani/eoagritwin/et/Sentinel3//LST/LST_values/tempDump/'\n",
    "\n",
    "\n",
    "# get all highRes datasets: S2 composites, aspect, ratio and incedence for the tile/time and stack them (in a composite if more than one tile is processed)\n",
    "# set the highRes S2 tiles that will be processed\n",
    "tiles_to_process = createFORCEtileLIST(list(bran['Tile_X']),\n",
    "                                        list(bran['Tile_Y']))\n",
    "\n",
    "\n",
    "# tiles_to_process = get_forceTSI_output_Tiles(getFilelist(path_to_slope, '.tif'))\n",
    "\n",
    "# slope-tiles\n",
    "slopes = [file for file in getFilelist(path_to_slope, '.tif') if any(tile in file for tile in tiles_to_process)] # if any tile name is in file\n",
    "# aspect-tiles\n",
    "aspects = [file for file in getFilelist(path_to_aspect, '.tif') if any(tile in file for tile in tiles_to_process)] # if any tile name is in file\n",
    "\n",
    "# get those tiles (and composite if more than one tile is provided)\n",
    "if len(tiles_to_process) == 1:\n",
    "    \n",
    "    slope_path = slopes[0]\n",
    "    aspect_path = aspects[0]\n",
    "\n",
    "else:\n",
    "    slope_path = f'{temp_dump}SLOPE.vrt'\n",
    "    gdal.BuildVRT(slope_path, slopes)\n",
    "\n",
    "    aspect_path = f'{temp_dump}ASPECT.vrt'\n",
    "    gdal.BuildVRT(aspect_path, aspects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "189c636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all dates of composites are the same :)\n",
      "Vrt might already exist - please check!!\n",
      "['BLU', 'GRN', 'NIR', 'RE1', 'RE2', 'RE3', 'RED', 'SW1', 'SW2']\n"
     ]
    }
   ],
   "source": [
    "# year \n",
    "year = 2019#range(2017,2025):\n",
    "  \n",
    "# paths\n",
    "path_to_S2_tiles = f'/data/Aldhani/eoagritwin/force/output/Guzinski/{year}/'\n",
    "\n",
    "\n",
    "##### which tiles should be processed\n",
    "# get a list with all available tiles\n",
    "files = getFilelist(f'{path_to_S2_tiles}/tiles', '.tif', deep=True) \n",
    "files = [file for file in files if any(tile in file for tile in tiles_to_process)]\n",
    "date_list = check_forceTSI_compositionDates(files)\n",
    "\n",
    "\n",
    "#### S2 composites are time sensitive (need to be aligned with date of LST observation), so is incidence\n",
    "\n",
    "for date in date_list:\n",
    "# date = date_list[0] # will be replaced through loop\n",
    "    if date != '20190705':\n",
    "        continue\n",
    "    # get those tiles (and composite if more than one tile is provided)\n",
    "    if len(tiles_to_process) == 1:\n",
    "\n",
    "        tilesS2 = [file for file in getFilelist(path_to_S2_tiles, '.tif', deep=True) if tiles_to_process[0] in file and f'{date}.tif' in file]\n",
    "        S2_path = f'{temp_dump}S2_{date}.vrt'\n",
    "        gdal.BuildVRT(S2_path, tilesS2)\n",
    "\n",
    "    else:\n",
    "        tilesS2 = [file for file in getFilelist(path_to_S2_tiles, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and f'{date}.tif' in file] \n",
    "        force_to_vrt(tilesS2,\n",
    "                getCOLORSinOrderFORCELIST(tilesS2, list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)), single=False),\n",
    "                f'{temp_dump}S2_{date}',\n",
    "                False,\n",
    "                bandnames= list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)))\n",
    "        print(list(dict.fromkeys(tile.split('SEN2L_')[-1].split('_TSI')[0] for tile in tilesS2)))\n",
    "        S2_path = [file for file in getFilelist(f'{temp_dump}S2_{date}', '.vrt', deep=True) if '_Cube' in file][0]\n",
    "        \n",
    "        # determine LST and incidence files associated with respective S2 composite\n",
    "    band_dict = transform_compositeDate_into_LSTbands(date, 4)\n",
    "\n",
    "\n",
    "    # stat used for compositing\n",
    "    for comp_stat in ['minVZA', 'maxLST']:\n",
    "        path_to_incident = f'/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/INCIDENCE/{comp_stat}/{year}/'\n",
    "        path_to_LST = f'/data/Aldhani/eoagritwin/et/Sentinel3/LST/LST_values/{comp_stat}/{year}/'\n",
    "\n",
    "        # get all LST bands that can be sharped with the S2 composite at this date (and sun angle incidence files as well, as they are dependent on that date\n",
    "        incid_dates = []\n",
    "        LSTs = []\n",
    "\n",
    "        for k, v in band_dict.items():\n",
    "            month = v['month']\n",
    "            band = int(v['band'])\n",
    "            v_path = f'{path_to_LST}Daily_LST_{comp_stat}_{year}_{month}.tif'\n",
    "            ds = gdal.Open(v_path, 0)\n",
    "            LST_arr = ds.GetRasterBand(band).ReadAsArray() # store as single Tiff in temp\n",
    "            makeTif_np_to_matching_tif(LST_arr, v_path, f'{temp_dump}Daily_LST_{comp_stat}_{year}_{month}_{band:02d}.tif')\n",
    "\n",
    "            # store the paths for selecting incidence for corresponding LST\n",
    "            incid_dates.append(f'{year}_{month}_{band:02d}.tif')\n",
    "            LSTs.append(f'{temp_dump}Daily_LST_{comp_stat}_{year}_{month}_{band:02d}.tif')\n",
    "            ##### loop over the LST files and go\n",
    "\n",
    "        for idx, LST_file in enumerate(LSTs):\n",
    "            # incidence-tiles\n",
    "            incids = [file for file in getFilelist(path_to_incident, '.tif', deep=True) if any(tile in file for tile in tiles_to_process) and incid_dates[idx] in file] \n",
    "            \n",
    "            # get those tiles (and composite if more than one tile is provided)\n",
    "            if len(tiles_to_process) == 1:\n",
    "                incid_path = incids[0]\n",
    "\n",
    "            else:\n",
    "                incid_path = f'{temp_dump}INCIDENCE.vrt'\n",
    "                gdal.BuildVRT(incid_path, incids)\n",
    "\n",
    "            # sanity check for incidence and LST date\n",
    "            if (LSTs[idx].split(f'{year}')[-1] == incids[0].split(f'{year}')[-1]):\n",
    "                \n",
    "                # get LST file\n",
    "                lowRes_path = LSTs[idx]\n",
    "                # create highRes file through exapnding the vrt of S2\n",
    "                highRes_path = f'{temp_dump}HIGHRES.vrt'\n",
    "                gdal.BuildVRT(highRes_path, [S2_path, slope_path, aspect_path, incid_path], separate=True)\n",
    "            else:\n",
    "                raise ValueError('Something is seriously wrong with the alignment of LST and incidence dates!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa87b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = 0\n",
    "for movWin in range(20,55,5):\n",
    "    for cv in range(5,40,5):\n",
    "        for regrat in np.arange(0.1, 0.35, 0.05):\n",
    "                a += 1\n",
    "print(a)                           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

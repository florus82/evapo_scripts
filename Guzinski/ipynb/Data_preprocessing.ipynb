{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32a344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.dicts_and_lists import *\n",
    "from helperToolz.guzinski import * \n",
    "from other_repos.pyDMS.pyDMS.pyDMS import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb77c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m aspect_path = \u001b[33m'\u001b[39m\u001b[33m/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/ASPECT/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m slope_path = \u001b[33m'\u001b[39m\u001b[33m/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/SLOPE/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m incidence_path = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/INCIDENCE/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtile\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# first, all files for months outside of studay aim will be deleted to save storgage\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# reduce_forceTSI_output_to_validmonths(f'{base_path}{year}/tiles', 4, 10)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAll FORCE files outside April-October deleted\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'tile' is not defined"
     ]
    }
   ],
   "source": [
    "# define the year you are working on \n",
    "year = 2019\n",
    "\n",
    "base_path = '/data/Aldhani/eoagritwin/force/output/Guzinski/'\n",
    "comp_stat = 'max'\n",
    "LST_path = '/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/LST/daily_observations_all/'\n",
    "temp_dump = '/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/LST/tempDump/'\n",
    "\n",
    "aspect_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/ASPECT/'\n",
    "slope_path = '/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/SLOPE/'\n",
    "incidence_path = f'/data/Aldhani/eoagritwin/et/Auxiliary/DEM/Force_Tiles/INCIDENCE/{tile}/{year}'\n",
    "\n",
    "\n",
    "# first, all files for months outside of studay aim will be deleted to save storgage\n",
    "# reduce_forceTSI_output_to_validmonths(f'{base_path}{year}/tiles', 4, 10)\n",
    "print('All FORCE files outside April-October deleted')\n",
    "\n",
    "# get a list with all available tiles\n",
    "files = getFilelist(f'{base_path}{year}/tiles', '.tif', deep=True) \n",
    "unique_tiles = get_forceTSI_output_Tiles(files)\n",
    "print(f'There are {len(unique_tiles)} tiles available for processing for the year {year}')\n",
    "\n",
    "# check if they contain composites for the same dates so that they can be stacked in the mosaiked\n",
    "date_list = check_forceTSI_compositionDates(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886991ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the LST file, aspect, ratio and incedence for the tile/time and stackem\n",
    "# loop over the adequate bands from monthly LST stack (each band corresponds to the respective day of that month), asepct, ratio & incidence files\n",
    "\n",
    "tiles_to_process = createFORCEtileLIST([67, 68, 67, 68],\n",
    "                                       [41, 41, 42, 42])\n",
    "\n",
    "# for tile_processing in tiles_to_process:\n",
    "#     for date in date_list:\n",
    "\n",
    "tile_processing = tiles_to_process\n",
    "date = date_list[0] # will be replaced through loop\n",
    "\n",
    "band_dict = transform_compositeDate_into_LSTbands(date, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac40445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/users/potzschf/conda/envs/workhorse/lib/python3.12/site-packages/osgeo/gdal.py:311: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# loop over all associated LST bands, as they are the only variable that changes (together with INCIDENCE, which will be loaded inside this loop)\n",
    "for k, v in band_dict.items():\n",
    "       month = v['month']\n",
    "       band = int(v['band'])\n",
    "       v_path = f'/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/LST/daily_observations_all/{year}/Daily_LST_{comp_stat}_{year}_{month}.tif'\n",
    "       ds = gdal.Open(v_path, 0)\n",
    "       LST_arr = ds.GetRasterBand(band).ReadAsArray() # store as single Tiff in temp\n",
    "       makeTif_np_to_matching_tif(LST_arr, v_path, f'{temp_dump}Daily_LST_{comp_stat}_{year}_{month}_{band}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10be0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_dict = {'lst_april': {'month': 'April'}}\n",
    "for k, v in band_dict.items():\n",
    "    year = 2019\n",
    "    month = v['month']\n",
    "    path = f'/data/test/{year}/file_{month}.tif'\n",
    "    print(\"DEBUG PATH:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ed578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only working for growing season, does not work across years!!!!!!\n",
    "for idx in range(index_in_sequence - 4, index_in_sequence + 5):\n",
    "    if dicti[idx]['month'] in ['February', 'November']:\n",
    "        continue\n",
    "    else:\n",
    "        print(dicti[idx]['month'])\n",
    "        print(dicti[idx]['band'])\n",
    "    #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f809b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates from FORCE 10 day interpolations and make stacked tifs\n",
    "for tile in tiles:\n",
    "  for unique_day in unique_days:\n",
    "    stack_tifs(sorted([file for file in files if unique_day in file and tile in file]), f'/data/{origin}force/output/Guzinski/1TileTest/{tile}_{unique_day}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd543292",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_2Tiles = sorted([file for file in files for tile in tiles if tile in file and unique_days[12] in file])\n",
    "files_2Tiles = [files_2Tiles[i] for i in [0,10,1,11,2,12,3,13,4,14,5,15,6,16,7,17,8,18]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    " # tiles = list(set([file.split('output/')[-1].split('/')[1].split('/')[0] for file in list_of_forcefiles]))\n",
    "    \n",
    "\n",
    "        # make paths in vrts relative\n",
    "        vrts = getFilelist(outDir, '.vrt')\n",
    "        for vrt in vrts:\n",
    "            convertVRTpathsTOrelative(vrt)\n",
    "        nums = [int(vrt.split('_')[-1].split('.')[0]) for vrt in vrts]\n",
    "        vrts_sorted = sortListwithOtherlist(nums, vrts)[-1]\n",
    "        print('paths in vrts made relative')\n",
    "        \n",
    "        vrt = gdal.BuildVRT(f'{outDir}{force_folder_name}_Cube.vrt', vrts_sorted, separate = True)\n",
    "        vrt = None\n",
    "        # convertVRTpathsTOrelative(f'{outDir}{force_folder_name}_Cube.vrt')\n",
    "        print('overlord vrt created')\n",
    "        if pyramids:\n",
    "            # build pyramids\n",
    "            vrtPyramids(f'{outDir}{force_folder_name}_Cube.vrt')\n",
    "            print('VRT created with pyramids')\n",
    "    else:\n",
    "        print('Vrt might already exist - please check!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe22669",
   "metadata": {},
   "outputs": [],
   "source": [
    "highResFilename1 = '/data/Aldhani/eoagritwin/force/output/Guzinski/1TileTest/X0067_Y0042_20190630.tif'\n",
    "highResFilename2 = '/data/Aldhani/eoagritwin/force/output/Guzinski/1TileTest/X0068_Y0042_20190630.tif'\n",
    "lowResFilename = '/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/LST/daily_observations_all/2019/Daily_LST_means_2019_July.tif'\n",
    "\n",
    "outputFilename = '/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/LST/test6_1.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True\n",
    "\n",
    "commonOpts = {\"highResFiles\":               [highResFilename1, highResFilename2],#[highResFilename],\n",
    "                \"lowResFiles\":              [lowResFilename, lowResFilename],\n",
    "                \"lowResQualityFiles\":         [],# [lowResMaskFilename],\n",
    "                \"lowResGoodQualityFlags\":     [],#[255],\n",
    "                \"cvHomogeneityThreshold\":     0,\n",
    "                \"movingWindowSize\":           15,\n",
    "                \"disaggregatingTemperature\":  True}\n",
    "dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                'activation':                 'tanh'}\n",
    "nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                \"regressorOpt\":               sknnOpts}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if useDecisionTree:\n",
    "    opts = commonOpts.copy()\n",
    "    opts.update(dtOpts)\n",
    "    disaggregator = DecisionTreeSharpener(**opts)\n",
    "else:\n",
    "    opts = commonOpts.copy()\n",
    "    opts.update(nnOpts)\n",
    "    disaggregator = NeuralNetworkSharpener(**opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976021f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training regressor...\")\n",
    "disaggregator.trainSharpener()\n",
    "print(\"Sharpening...\")\n",
    "downscaledFile = disaggregator.applySharpener(highResFilename1, lowResFilename)\n",
    "print(\"Residual analysis...\")\n",
    "residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                               # lowResMaskFilename,\n",
    "                                                                doCorrection=True)\n",
    "print(\"Saving output...\")\n",
    "highResFile = gdal.Open(highResFilename1)\n",
    "if correctedImage is not None:\n",
    "    outImage = correctedImage\n",
    "else:\n",
    "    outImage = downscaledFile\n",
    "# outData = utils.binomialSmoother(outData)\n",
    "outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                        outImage.GetGeoTransform(),\n",
    "                        outImage.GetProjection(),\n",
    "                        outputFilename)\n",
    "residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                            residualImage.GetGeoTransform(),\n",
    "                            residualImage.GetProjection(),\n",
    "                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                            os.path.splitext(outputFilename)[1])\n",
    "\n",
    "outFile = None\n",
    "residualFile = None\n",
    "downsaceldFile = None\n",
    "highResFile = None\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

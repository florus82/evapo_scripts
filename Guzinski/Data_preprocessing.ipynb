{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32a344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.evapo import *\n",
    "\n",
    "workhorse = True\n",
    "\n",
    "if workhorse:\n",
    "    origin = 'Aldhani/eoagritwin/'\n",
    "else:\n",
    "    origin = ''\n",
    "\n",
    "import re\n",
    "from other_repos.pyDMS.pyDMS.pyDMS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb77c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_force_to_validmonths(f'/data/{origin}force/output/Guzinski/1TileTest/',3,8)\n",
    "files = getFilelist(f'/data/{origin}force/output/Guzinski/1TileTest/', '.tif', deep=True) \n",
    "tiles = ['X0067_Y0042', 'X0068_Y0042']\n",
    "unique_days = get_forceTSI_output_DOYS(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f809b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates from FORCE 10 day interpolations and make stacked tifs\n",
    "\n",
    "\n",
    "for tile in tiles:\n",
    "  for unique_day in unique_days:\n",
    "    stack_tifs(sorted([file for file in files if unique_day in file and tile in file]), f'/data/{origin}force/output/Guzinski/1TileTest/{tile}_{unique_day}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd543292",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_2Tiles = sorted([file for file in files for tile in tiles if tile in file and unique_days[12] in file])\n",
    "files_2Tiles = [files_2Tiles[i] for i in [0,10,1,11,2,12,3,13,4,14,5,15,6,16,7,17,8,18]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a44dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '365_HL_TSA_SEN2L_BLU_TSI_20190630'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mforce_order_BGRBNR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles_2Tiles\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/helperToolz/helpsters.py:630\u001b[39m, in \u001b[36mforce_order_BGRBNR\u001b[39m\u001b[34m(list_of_forcefiles)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m tiles:\n\u001b[32m    629\u001b[39m     tilefiles = [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m list_of_forcefiles \u001b[38;5;28;01mif\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m file]\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     tilefilesL.append(\u001b[43mgetBluGrnRedBnrANDmoreFORCEList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtilefiles\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tilefilesL\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/helperToolz/helpsters.py:550\u001b[39m, in \u001b[36mgetBluGrnRedBnrANDmoreFORCEList\u001b[39m\u001b[34m(filelist)\u001b[39m\n\u001b[32m    547\u001b[39m sw1 = [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m filelist \u001b[38;5;28;01mif\u001b[39;00m file.split(\u001b[33m'\u001b[39m\u001b[33mSEN2L_\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m].split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mSW1\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    548\u001b[39m sw2 = [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m filelist \u001b[38;5;28;01mif\u001b[39;00m file.split(\u001b[33m'\u001b[39m\u001b[33mSEN2L_\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m].split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mSW2\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m blu = sortListwithOtherlist([\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m blu], blu)[-\u001b[32m1\u001b[39m]\n\u001b[32m    551\u001b[39m grn = sortListwithOtherlist([\u001b[38;5;28mint\u001b[39m(t.split(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m].split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m grn], grn)[-\u001b[32m1\u001b[39m]\n\u001b[32m    552\u001b[39m red = sortListwithOtherlist([\u001b[38;5;28mint\u001b[39m(t.split(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m].split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m red], red)[-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: '365_HL_TSA_SEN2L_BLU_TSI_20190630'"
     ]
    }
   ],
   "source": [
    "force_order_BGRBNR(files_2Tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd46b5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Aldhani/eoagritwin/force/output/Guzinski/1TileTest/Force_X_from_67_to_68_Y_from_42_to_42/\n",
      "single vrts created\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    " # tiles = list(set([file.split('output/')[-1].split('/')[1].split('/')[0] for file in list_of_forcefiles]))\n",
    "    \n",
    "\n",
    "        # make paths in vrts relative\n",
    "        vrts = getFilelist(outDir, '.vrt')\n",
    "        for vrt in vrts:\n",
    "            convertVRTpathsTOrelative(vrt)\n",
    "        nums = [int(vrt.split('_')[-1].split('.')[0]) for vrt in vrts]\n",
    "        vrts_sorted = sortListwithOtherlist(nums, vrts)[-1]\n",
    "        print('paths in vrts made relative')\n",
    "        \n",
    "        vrt = gdal.BuildVRT(f'{outDir}{force_folder_name}_Cube.vrt', vrts_sorted, separate = True)\n",
    "        vrt = None\n",
    "        # convertVRTpathsTOrelative(f'{outDir}{force_folder_name}_Cube.vrt')\n",
    "        print('overlord vrt created')\n",
    "        if pyramids:\n",
    "            # build pyramids\n",
    "            vrtPyramids(f'{outDir}{force_folder_name}_Cube.vrt')\n",
    "            print('VRT created with pyramids')\n",
    "    else:\n",
    "        print('Vrt might already exist - please check!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe22669",
   "metadata": {},
   "outputs": [],
   "source": [
    "highResFilename1 = '/data/Aldhani/eoagritwin/force/output/Guzinski/1TileTest/X0067_Y0042_20190630.tif'\n",
    "highResFilename2 = '/data/Aldhani/eoagritwin/force/output/Guzinski/1TileTest/X0068_Y0042_20190630.tif'\n",
    "lowResFilename = '/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/LST/daily_observations_all/2019/Daily_LST_means_2019_July.tif'\n",
    "\n",
    "outputFilename = '/data/Aldhani/eoagritwin/et/Sentinel3/tiffs/LST/test6_1.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "useDecisionTree = True\n",
    "\n",
    "commonOpts = {\"highResFiles\":               [highResFilename1, highResFilename2],#[highResFilename],\n",
    "                \"lowResFiles\":              [lowResFilename, lowResFilename],\n",
    "                \"lowResQualityFiles\":         [],# [lowResMaskFilename],\n",
    "                \"lowResGoodQualityFlags\":     [],#[255],\n",
    "                \"cvHomogeneityThreshold\":     0,\n",
    "                \"movingWindowSize\":           15,\n",
    "                \"disaggregatingTemperature\":  True}\n",
    "dtOpts =     {\"perLeafLinearRegression\":    True,\n",
    "                \"linearRegressionExtrapolationRatio\": 0.25}\n",
    "sknnOpts =   {'hidden_layer_sizes':         (10,),\n",
    "                'activation':                 'tanh'}\n",
    "nnOpts =     {\"regressionType\":             REG_sklearn_ann,\n",
    "                \"regressorOpt\":               sknnOpts}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "if useDecisionTree:\n",
    "    opts = commonOpts.copy()\n",
    "    opts.update(dtOpts)\n",
    "    disaggregator = DecisionTreeSharpener(**opts)\n",
    "else:\n",
    "    opts = commonOpts.copy()\n",
    "    opts.update(nnOpts)\n",
    "    disaggregator = NeuralNetworkSharpener(**opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976021f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training regressor...\")\n",
    "disaggregator.trainSharpener()\n",
    "print(\"Sharpening...\")\n",
    "downscaledFile = disaggregator.applySharpener(highResFilename1, lowResFilename)\n",
    "print(\"Residual analysis...\")\n",
    "residualImage, correctedImage = disaggregator.residualAnalysis(downscaledFile, lowResFilename,\n",
    "                                                               # lowResMaskFilename,\n",
    "                                                                doCorrection=True)\n",
    "print(\"Saving output...\")\n",
    "highResFile = gdal.Open(highResFilename1)\n",
    "if correctedImage is not None:\n",
    "    outImage = correctedImage\n",
    "else:\n",
    "    outImage = downscaledFile\n",
    "# outData = utils.binomialSmoother(outData)\n",
    "outFile = utils.saveImg(outImage.GetRasterBand(1).ReadAsArray(),\n",
    "                        outImage.GetGeoTransform(),\n",
    "                        outImage.GetProjection(),\n",
    "                        outputFilename)\n",
    "residualFile = utils.saveImg(residualImage.GetRasterBand(1).ReadAsArray(),\n",
    "                            residualImage.GetGeoTransform(),\n",
    "                            residualImage.GetProjection(),\n",
    "                            os.path.splitext(outputFilename)[0] + \"_residual\" +\n",
    "                            os.path.splitext(outputFilename)[1])\n",
    "\n",
    "outFile = None\n",
    "residualFile = None\n",
    "downsaceldFile = None\n",
    "highResFile = None\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.evapo import *\n",
    "import geopandas as gpd\n",
    "import tarfile\n",
    "from rasterio.transform import from_bounds\n",
    "import rasterio\n",
    "\n",
    "workhorse = True\n",
    "\n",
    "if workhorse:\n",
    "    origin = 'Aldhani/eoagritwin/'\n",
    "else:\n",
    "    origin = ''\n",
    "\n",
    "utm_to_epsg = {\n",
    "    '28': 32628,  # Western Portugal, Azores\n",
    "    '29': 32629,  # Western Spain, Portugal\n",
    "    '30': 32630,  # Spain, France, UK\n",
    "    '31': 32631,  # France, Benelux, Germany, Western Norway\n",
    "    '32': 32632,  # Germany, Denmark, Switzerland, Italy, Austria\n",
    "    '33': 32633,  # Central Europe: Poland, Czechia, Hungary, Croatia, Sweden, Norway\n",
    "    '34': 32634,  # Eastern Europe: Finland, Baltic States, Romania\n",
    "    '35': 32635,  # Western Russia, Ukraine\n",
    "    '36': 32636,  # Russia, Black Sea region\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b941a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get path and rows of scenes that have data for the chosen AOI (e.g. Brandenburg)\n",
    "\n",
    "# load shapefiles and \n",
    "ger = gpd.read_file(f'/data/{origin}misc/gadm41_DEU_shp/gadm41_DEU_1.shp')\n",
    "\n",
    "state = 'Brandenburg'\n",
    "aoi = ger[ger['NAME_1'] == state]\n",
    "\n",
    "orbits = gpd.read_file(f'/data/{origin}misc/WRS2_descending_0/WRS2_descending.shp')\n",
    "# check projections\n",
    "if aoi.crs != orbits.crs:\n",
    "    aoi = aoi.to_crs(orbits.crs)\n",
    "\n",
    "# find overlapping paths/rows\n",
    "#intersecting = orbits[orbits.intersects(aoi.unary_union)]\n",
    "intersecting = gpd.sjoin(orbits, aoi, how=\"inner\", predicate=\"intersects\")\n",
    "path_rows = [[p, r] for p, r in zip(intersecting['PATH'], intersecting['ROW'])]\n",
    "# make sure, paths and rows have the correct format\n",
    "path_rows = [f'{str(p).zfill(3)}{str(r).zfill(3)}' for p, r in path_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ff14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4161175/1705390476.py:25: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(tempF)\n"
     ]
    }
   ],
   "source": [
    "# get all paths from downloaded products --> subsetted to paths and rows\n",
    "landsat_files = getFilelist(f'/data/{origin}et/Landsat/raw/', '.tar.gz', deep=True)\n",
    "\n",
    "# create a look-up dictionary for time subsets\n",
    "lookUp = LandsatETFileManager(landsat_files)\n",
    "\n",
    "#### do the compositing monthly\n",
    "year = 2024\n",
    "month = 8\n",
    "\n",
    "# check if temp_folder is empty and delete everything if not\n",
    "tempF = f'/data/{origin}et/Landsat/extracts/'\n",
    "if len(getFilelist(tempF, '.nc')) > 0:\n",
    "    for end in ['.nc', '.xml', '.txt']:\n",
    "        for file in getFilelist(tempF, end):\n",
    "            os.remove(file)\n",
    "    print('kill complete')\n",
    "\n",
    "# subset data for year and month and extract\n",
    "year_month = lookUp.get_by_year_and_month(year, month)\n",
    "year_month_path_row = [scene for scene in year_month for pr in path_rows if pr in scene]\n",
    "\n",
    "for landsat_file in year_month_path_row:\n",
    "    with tarfile.open(landsat_file, 'r:gz') as tar:\n",
    "        tar.extractall(tempF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95190acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file paths\n",
    "files_nc = getFilelist(f'/data/{origin}et/Landsat/extracts/', '.nc')\n",
    "files_xml = getFilelist(f'/data/{origin}et/Landsat/extracts/', '.xml')\n",
    "datasets = []\n",
    "\n",
    "bound_coords = {\n",
    "    'UTM': [],\n",
    "    'UL_X': [],\n",
    "    'UL_Y': [],\n",
    "    'LR_X': [],\n",
    "    'LR_Y': []\n",
    "}\n",
    "\n",
    "# loop over all extracted files and give spatial ref \n",
    "for f_nc in files_nc:\n",
    "\n",
    "    ds = xr.open_dataset(f_nc)\n",
    "    da = ds['ETA']\n",
    "    if len(np.unique(da.values)) == 1:\n",
    "        continue\n",
    "    # find UL corner coordinates to find the most outer one for common grid\n",
    "    utm_zone, ul_x, ul_y, lr_x, lr_y = get_UTM_zone_and_corners_from_xml(f_nc, files_xml)\n",
    "   \n",
    "    da.rio.set_spatial_dims(x_dim=\"XDim_ETA\", y_dim=\"YDim_ETA\", inplace=True)\n",
    "    da.rio.write_crs(f'EPSG:{utm_to_epsg[utm_zone]}', inplace=True)\n",
    "    datasets.append(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a074a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_arrays = []\n",
    "\n",
    "for counti, xr_raster in enumerate(datasets):\n",
    "    src_ds = xarray_to_gdal_mem(xr_raster)\n",
    "    warped_ds = warp_to_template(src_ds, f'/data/{origin}et/Auxiliary/Landsat_GER_mask/states/{state}.tif')\n",
    "    arr = warped_ds.GetRasterBand(1).ReadAsArray()\n",
    "    warped_arrays.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2000af23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4161175/330774565.py:3: RuntimeWarning: All-NaN slice encountered\n",
      "  median  = np.nanmedian(warped_stack, axis=2)\n"
     ]
    }
   ],
   "source": [
    "warped_stack = np.dstack(warped_arrays)\n",
    "warped_stack[warped_stack == 0.0] = np.nan\n",
    "median  = np.nanmedian(warped_stack, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27088126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask output\n",
    "mask_ds = gdal.Open(f'/data/{origin}et/Auxiliary/Landsat_GER_mask/states/{state}.tif')\n",
    "mask_arr = mask_ds.GetRasterBand(1).ReadAsArray()\n",
    "median_masked = median * mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3500e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "makeTif_np_to_matching_tif(median_masked, \n",
    "                            f'/data/{origin}et/Auxiliary/Landsat_GER_mask/states/{state}.tif',\n",
    "                           f'/data/{origin}et/Landsat/composites/{year}_{month:02d}_median_masked.tif', 0, gdalType=gdal.GDT_Float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

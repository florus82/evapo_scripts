{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd8f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.evapo import *\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "workhorse = True\n",
    "\n",
    "if workhorse:\n",
    "    origin = 'Aldhani/eoagritwin/'\n",
    "else:\n",
    "    origin = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28eb4eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets available for training\n",
      "\n",
      "     S2:EVI S2:NDM S2:NDV S2:TCB S2:TCG S2:TCW S3:mean S3:median\n",
      "Year                                                            \n",
      "2017      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n",
      "2018      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n",
      "2019      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n",
      "2020      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n",
      "2021      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n",
      "2022      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n",
      "2023      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n",
      "2024      ✔      ✔      ✔      ✔      ✔      ✔       ✔         ✔\n"
     ]
    }
   ],
   "source": [
    "# get files and check if years are same for both sensors. Also check what indices and metrics are available\n",
    "training_files = getFilelist('/data/Aldhani/eoagritwin/et/Training_ML/training_data/', '.parquet')\n",
    "\n",
    "indices_by_year = defaultdict(set)\n",
    "\n",
    "for file in training_files:\n",
    " \n",
    "    match  = re.search(r'/(S2|S3)_(\\d{4})(?:_([A-Za-z]{3,10}))?', file) # (?:_([A-Z]{3}))? --> the ? at the end makes the whole group optional, i.e. also files where \n",
    "                                                                    # only the first 2 groups match will be considered. the first question mark stops the loop from breaking,\n",
    "                                                                    # if a file with only the first 2 groups is encountered\n",
    "    if match:\n",
    "        sensor, year, index = match.groups()\n",
    "        if index:  # Only S2 has metrics in filename\n",
    "            indices_by_year[year].add(f'{sensor}:{index}')\n",
    "    \n",
    "\n",
    "# Get all unique indices\n",
    "all_indices = sorted({index for indices in indices_by_year.values() for index in indices})\n",
    "\n",
    "# Prepare a table: rows = years, columns = indices\n",
    "table_data = []\n",
    "for year in sorted(indices_by_year):\n",
    "    row = {index: '✔' if index in indices_by_year[year] else 'X' for index in all_indices}\n",
    "    row['Year'] = year\n",
    "    table_data.append(row)\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(table_data)\n",
    "df = df.set_index('Year')\n",
    "print('\\nDatasets available for training\\n')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4438cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVI\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2017_EVI.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2018_EVI.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2019_EVI.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2020_EVI.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2021_EVI.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2022_EVI.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2023_EVI.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2024_EVI.parquet\n",
      "NDM\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2017_NDM.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2018_NDM.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2019_NDM.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2020_NDM.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2021_NDM.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2022_NDM.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2023_NDM.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2024_NDM.parquet\n",
      "NDV\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2017_NDV.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2018_NDV.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2019_NDV.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2020_NDV.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2021_NDV.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2022_NDV.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2023_NDV.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2024_NDV.parquet\n",
      "TCB\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2017_TCB.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2018_TCB.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2019_TCB.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2020_TCB.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2021_TCB.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2022_TCB.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2023_TCB.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2024_TCB.parquet\n",
      "TCG\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2017_TCG.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2018_TCG.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2019_TCG.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2020_TCG.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2021_TCG.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2022_TCG.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2023_TCG.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2024_TCG.parquet\n",
      "TCW\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2017_TCW.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2018_TCW.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2019_TCW.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2020_TCW.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2021_TCW.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2022_TCW.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2023_TCW.parquet\n",
      "/data/Aldhani/eoagritwin/et/Training_ML/training_data/S2_2024_TCW.parquet\n"
     ]
    }
   ],
   "source": [
    "# bring S2 together and in shape\n",
    "index_conti = []\n",
    "for index in [col.split(':')[-1] for col in df.columns[:-2]]:\n",
    "    print(index)\n",
    "    temp_conti = []\n",
    "    for file in training_files:\n",
    "        if index in file:\n",
    "            print(file)\n",
    "            dat = pd.read_parquet(file)\n",
    "            dat = dat.assign(year = re.search(r'_(\\d{4})_', file).group(1))\n",
    "            dat = dat[['year', 'doy', 'row', 'col', 'S2', 'index']]\n",
    "            dat = dat.rename(columns={'S2': file.split('_')[-1].split('.')[0]})\n",
    "            dat = dat.drop('index', axis=1)\n",
    "            dat.dropna()\n",
    "            temp_conti.append(dat)\n",
    "    index_conti.append(pd.concat(temp_conti, ignore_index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0ab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "S2_block = index_conti[0]\n",
    "for i in range(1, len(index_conti)):\n",
    "    print(i)\n",
    "    S2_block = pd.merge(S2_block, index_conti[i], on=['row', 'col', 'doy', 'year'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a86968",
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_wide.to_parquet(f'/data/{origin}et/Training_ML/training_data/S3_powerblock.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3051a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "S2_years = [str(year) for year in range(2017,2025)]\n",
    "S2_indices = ['EVI', 'NDM', 'NDV', 'TCB', 'TCG', 'TCW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f48553",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r1 in range(1, len(S2_years) + 1):\n",
    "    for combo1 in itertools.combinations(S2_years, r1):\n",
    "        prefix = ' '.join(combo1)\n",
    "\n",
    "        # For each, combine with all non-empty combinations of list2\n",
    "        for r2 in range(1, len(S2_indices) + 1):\n",
    "            for combo2 in itertools.combinations(S2_indices, r2):\n",
    "                suffix = ' + '.join(combo2)\n",
    "                result.append(f'{prefix} with {suffix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "[file for file in training_files if any(substr in file for substr in S2_indices[2:4]) and any(substr in file for substr in S2_years[2:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88782ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_by_year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

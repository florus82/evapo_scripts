{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ee735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/potzschf/repos/')\n",
    "from helperToolz.helpsters import *\n",
    "from helperToolz.evapo import *\n",
    "from datetime import datetime\n",
    "workhorse = True\n",
    "\n",
    "if workhorse:\n",
    "    origin = 'Aldhani/eoagritwin/'\n",
    "else:\n",
    "    origin = ''\n",
    "\n",
    "def get_folders_in_dir(dir):\n",
    "    return [f for f in os.listdir(dir) if os.path.isdir(os.path.join(dir, f))]\n",
    "\n",
    "trash = '/data/Aldhani/eoagritwin/et/Auxiliary/trash/band_intermediate/'\n",
    "temp = '/data/Aldhani/eoagritwin/et/Auxiliary/trash/vrt/'\n",
    "os.makedirs(trash, exist_ok=True)\n",
    "os.makedirs(temp, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv for valid row_cols for samples to draw. They are based on the share of agriculture (HR Landcover maps) within a S3 pixel\n",
    "thresh_csv = pd.read_csv(f'/data/{origin}et/Auxiliary/landcover/csv/row_cols.csv')\n",
    "\n",
    "for col in thresh_csv.columns:\n",
    "    #print(f'finding indices for {col}')\n",
    "    nested = [entry.split('_') for entry in thresh_csv[col] if type(entry) == str]\n",
    "    rows, cols = zip(*nested)\n",
    "    #print(len(rows))\n",
    "# only use Thresh50, as all valid row_col will be here. For other THresh sets, a subset from this can be taken\n",
    "# this are the last instances of rows and cols\n",
    "rows = [int(row) for row in rows]\n",
    "cols = [int(col) for col in cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e51b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all data is there and get the the different stacks (indices)\n",
    "year = 2018\n",
    "force_path = f'/data/Aldhani/eoagritwin/force/output/S3/{year}/'\n",
    "folders = get_folders_in_dir(force_path)\n",
    "folder_to_clean = [os.path.join(force_path, folder) for folder in folders if len(getFilelist(os.path.join(force_path, folder), '.tif', deep=True)) != 6]\n",
    "if len(folder_to_clean) > 0:\n",
    "    raise ValueError('the folders do not contain the same number of images...')\n",
    "# for folder in folder_to_clean:\n",
    "#     [os.remove(file) for file in getFilelist(folder, '.tif', deep=True) if '20181001' in file]\n",
    "indices = list(set([file_annual.split('_')[-2] for file_annual in getFilelist(os.path.join(force_path, folders[0]), '.tif', deep=True)]))\n",
    "indices.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c600ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the bands in raster stacks that belong to the year of interest\n",
    "ds = gdal.Open(getFilelist(os.path.join(force_path, folders[0]), '.tif', deep=True)[0], 0)\n",
    "if ds.RasterCount > 366:\n",
    "    bandname = str(ds.GetRasterBand(93).GetDescription())\n",
    "    if bandname == f'{year}0101':\n",
    "        start_index = 93\n",
    "        end_index = 457\n",
    "        if year in [2016,2020,2024]:\n",
    "            end_index +=1\n",
    "    else:\n",
    "        raise ValueError('band for Jan 01 not found!')\n",
    "\n",
    "files = [getFilelist(os.path.join(force_path, folder), '.tif', deep=True) for folder in folders]\n",
    "files = [file for list in files for file in list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index in indices:\n",
    "index = indices[1]\n",
    "index_files = [file for file in files if index in file]\n",
    "conti = []\n",
    "for band_number in range(start_index,end_index+1,1):\n",
    "    # create daily vrts and extract\n",
    "\n",
    "    for i, tif in enumerate(index_files):\n",
    "        output = trash + tif.split('/')[-1].split('.')[0] + '_' + str(band_number) + '_' + str(i) + '.tif'\n",
    "        gdal.Translate(output, tif, bandList=[band_number])\n",
    "\n",
    "    # Now build VRT\n",
    "    vrt_options = gdal.BuildVRTOptions(separate=False)\n",
    "    vrt_ds = gdal.BuildVRT(f'{temp}{year}_{index}_{band_number}.vrt', getFilelist(trash, '.tif'), options=vrt_options)\n",
    "    # vrt_ds.FlushCache()\n",
    "    # vrt = gdal.Open(f'{temp}{year}_{index}_{band_number}.vrt')\n",
    "    warpi = warp_to_template(vrt_ds, \n",
    "            '/data/Aldhani/eoagritwin/et/Auxiliary/S3_tif_GER_maks/powermask.tif',\n",
    "            mask_path='/data/Aldhani/eoagritwin/et/Auxiliary/S3_tif_GER_maks/powermask.tif',\n",
    "            #outPath=f'/data/Aldhani/eoagritwin/et/FORCE/vrt_dumps/{year}_{index}_{band_number}.tif',\n",
    "            outType=gdal.GDT_Int16)\n",
    "    conti.append(warpi)\n",
    "    [os.remove(file) for file in getFilelist(trash, '.tif')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86006537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.append(warpi[rows,cols])\n",
    "arr = np.stack(vals)\n",
    "mask = np.all(arr == -9999, axis=0)\n",
    "small_arr = arr[:, ~mask]\n",
    "\n",
    "np.save(f'/data/{origin}et/Auxiliary/dumps_for_training_collecting/{year}_{index}_X0063_Y0044_arr10', small_arr)\n",
    "nested_masked = [row_col for row_col, valid in zip(nested, ~mask) if valid]\n",
    "np.save(f'/data/{origin}et/Auxiliary/dumps_for_training_collecting/{year}_{index}_X0063_Y0044_rowcols10', nested_masked)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8347059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = np.load(f'/data/{origin}et/Auxiliary/dumps_for_training_collecting/2018_NDM.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20959ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['141', '846'], ['141', '847'], ['141', '848'], ['141', '849'], ['141', '851'], ['141', '852'], ['141', '853'], ['141', '854'], ['141', '855'], ['141', '856'], ['141', '859'], ['141', '860'], ['141', '861'], ['141', '863'], ['141', '864'], ['141', '865'], ['141', '866'], ['141', '867'], ['141', '870'], ['141', '871'], ['141', '875'], ['141', '876'], ['141', '877'], ['141', '878'], ['141', '881'], ['141', '882'], ['141', '883'], ['141', '885'], ['141', '886'], ['141', '888'], ['141', '889'], ['141', '890'], ['141', '891'], ['141', '892'], ['141', '893'], ['141', '894'], ['141', '895'], ['141', '896'], ['141', '897'], ['141', '898'], ['141', '899'], ['141', '900'], ['141', '901'], ['141', '902'], ['141', '905'], ['141', '906'], ['141', '907'], ['141', '908'], ['141', '909'], ['141', '910'], ['141', '911'], ['141', '913'], ['141', '914'], ['142', '346'], ['142', '347'], ['142', '348'], ['142', '349'], ['142', '350']]\n",
      "ROWS: [141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 142, 142, 142, 142, 142]  COLS: [846, 847, 848, 849, 851, 852, 853, 854, 855, 856, 859, 860, 861, 863, 864, 865, 866, 867, 870, 871, 875, 876, 877, 878, 881, 882, 883, 885, 886, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 905, 906, 907, 908, 909, 910, 911, 913, 914, 346, 347, 348, 349, 350]\n"
     ]
    }
   ],
   "source": [
    "a=9542\n",
    "b=9600\n",
    "print(nested[a:b])\n",
    "print(f'ROWS: {rows[a:b]}  COLS: {cols[a:b]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_path = '/data/Aldhani/eoagritwin/force/output/S3/2018/X0063_Y0044/TSI/'\n",
    "files = getFilelist(force_path, '.tif')\n",
    "# delete all other files\n",
    "[RasterKiller(file) for file in files if str(year) not in file.split('_')[-1]]\n",
    "files = getFilelist(force_path, '.tif')\n",
    "files_annual = [file for file in files if str(year) in file]\n",
    "indices = list(set([file_annual.split('_')[-3] for file_annual in files_annual]))\n",
    "indices.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rc100[0:10,5])\n",
    "print(rc10[0:10,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open(index_file,0)\n",
    "# Get list of all metadata domains\n",
    "domains = ds.GetMetadataDomainList()\n",
    "\n",
    "# Collect metadata from all domains\n",
    "metadata_all = {}\n",
    "\n",
    "for domain in domains:\n",
    "    metadata = ds.GetMetadata(domain)\n",
    "    metadata_all[domain] = metadata\n",
    "    print(f\"--- Metadata for domain: {domain} ---\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()\n",
    "\n",
    "band = ds.GetRasterBand(1)\n",
    "# Band-specific metadata\n",
    "print(\"Band Metadata:\", band.GetMetadata())\n",
    "\n",
    "# Band-specific statistics and other info\n",
    "print(\"Min/Max:\", band.GetMinimum(), band.GetMaximum())\n",
    "print(\"Scale:\", band.GetScale())       # for scaled values\n",
    "print(\"Offset:\", band.GetOffset())\n",
    "print(\"Unit Type:\", band.GetUnitType())\n",
    "print(\"NoData Value:\", band.GetNoDataValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d916e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ds.GetRasterBand(1).ReadAsArray()\n",
    "# Replace nodata with NaN\n",
    "arr = np.where(arr == -9999, np.nan, arr)\n",
    "\n",
    "# Invert the log10 transform\n",
    "real_amplitude = 10 ** (arr-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(warpi))\n",
    "\n",
    "plt.imshow(warpi[300:335,580:640])\n",
    "plt.axis('off')  # Hide axis for cleaner image display\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dict of dicts: row_col â†’ {year: value}\n",
    "data_dict = {rc: {} for rc in row_col_list}\n",
    "\n",
    "for year, values in yearly_values.items():\n",
    "    for rc, val in zip(row_col_list, values):\n",
    "        data_dict[rc][year] = val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workhorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
